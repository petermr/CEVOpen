<html xmlns="http://www.w3.org/1999/xhtml"> <head> <style type="text/css">
      	     		 
      	    a                          {background : #ffffff; }
      	    article                    {border-style : dotted; border-width : 2px; }
		 	
		 	div                        {background : #ffffcc;}
		 	div.abstract-title         {font-weight : bold ; font-size : 16pt;}
		 	div.ack                    {border-style : solid ; border-color : red; margin : 2em; }
		 	div.article-meta           {border-style : solid; border-width : 1 pt; margin 1em;}
		 	div.boxed-text             {margin : 5em; border-style : solid;}
		 	div.contrib-group          {margin : 1em; }
		 	div.fig                    {border-style : solid; border-width : 2px; margin : 2em; }
		 	div.funding                {font-weight : bold ; font-size : 16pt;}
		 	div.given-names            {font-style : italic;}
		 	div.intro                  {border-style : inset; margin : 5px;}
		 	div.introduction           {border-style : inset; margin : 5px;}
		 	div.journal-meta           {border-style : solid; border-width : 1 pt; margin 1em;}
		 	div.journal-title-group    {background : #ffeeee;}
		 	div.article-title          {font-weight : bold ; font-size : 18pt;}
		 	div.kwd                    {font-style : italic}
		 	div.meta-name              {font-weight : bold ; font-size : 16pt;}
		 	div.name                   {font-weight : bold;}
		 	div.alt-title              {font-style : italic; font-size : 12px;}
		 	
		 	div.sec                    {border : 2px; margin 5px; padding 2px;}
		 	div.title                  {font-family : courier; font-weight : bold;
		 	                            font-size : 16pt; margin : 5px;}
		 	
		 	div.materials_methods      {border-style : double; margin : 5px; }
		 	div.methods                {border-style : double; margin : 5px; }
		 	
		 	div.results                {border-style : solid; margin : 5px;}
		 	div.background             {border-style : dotted; margin : 5px;}
		 	
		 	div.discussion             {border-style : groove; margin : 5px;}
		 	div.conclusion             {border-style : ridge; margin : 5px;}
		 	div.conclusions             {border-style : ridge; margin : 5px;}
		 	div.supplementary-material {border-style : inset; margin : 5px;}
		 	div.abbreviations          {border-style : double; border-color : red; margin : 5px;}
		 	div.competinginterests     {border-style : double; border-color : blue; margin : 5px;}
		 	div.acknowledgements       {border-style : double; border-color : green; margin : 5px;}
		 	div.authors_contributions   {border-style : double; border-color : purple; margin : 5px;}
		 	
		 	div.publisher              {border-style : outset; margin : 5px;}
		 	div.fn-type-conflict       {background : #f88; }
		 	div.fn-type-con            {background : #ddf; }
		 	div.fn-type-other          {background : #ddd; }
		 	
		 	div.unknown                {background : #ffd;
									 	  border-style : solid;
									 	  border-width : 1px;
									 	  padding : 2 px;}
		 	  
      	    table                      {background : #ffffdd;}
		 	tr                         {background : #ddddff; padding : 1px;}
		 	
		 	span                       {background : #ffcccc;}
		 	
		 	span.citation-author       {font-family : helvetica; background : #ffeeee;}
		 	span.collab                {background : #ddffff; }
		 	span.comment               {font-family : courier; font-size : 6px; background : #ffaaff;}
		 	span.contrib               {background : #ffffff;}
		 	span.corresp               {background : #ddffdd; }
		 	span.doi                   {background : #ffffff;}
		 	span.email                 {font-family : courier; }
		 	span.etal                  {font-style : italic;}
		 	span.fpage                 {font-family : courier;}
		 	span.given-names           {background : #ffffff;}
		 	span.iso-abbrev            {background : #ffffff;}
		 	span.issn-epub             {background : #ffffff;}
		 	span.issn-ppub             {background : #ffffff;}
		 	span.journal-title         {background : #ffffff;}
		 	span.lpage                 {font-family : courier;}
		 	span.mixed-article-title   {font-style : italic ;}
		 	span.nlm-ta                {background : #ffffff;}
		 	span.pmc                   {background : #ffffff;}
		 	span.pmcid                 {background : #ffffff;}
		 	span.pmid                  {background : #ffffff;}
		 	span.publisher             {background : #ffffff;}
		 	span.publisher-id          {background : #ffffff;}
		 	span.publisher-name        {background : #ffffff;}
		 	span.source                {background : #ffffff;}
		 	span.subject               {background : #ffffff;}
		 	span.surname               {background : #ffffff;}
		 	span.volume                {font-family : courier; font-weight : bold;}
		 	span.year                  {font-family : courier ; font-style : italic;}
			</style> </head> <body> <div class="front" title="front"> <div class="journal-meta" tagx="journal-meta" title="journal-meta"><span class="nlm-ta" title="nlm-ta">Sensors (Basel)</span><span class="iso-abbrev" title="iso-abbrev">Sensors (Basel)</span><span class="publisher-id" title="publisher-id">sensors</span><div class="journal-title-group" tagx="journal-title-group" title="journal-title-group"><span class="journal-title" tagx="journal-title" title="journal-title">Sensors (Basel, Switzerland)</span></div><span class="issn-epub" tagx="issn" title="issn-epub">1424-8220</span><div class="publisher" tagx="publisher" title="publisher"><span class="publisher-name" tagx="publisher-name" title="publisher-name">MDPI</span></div> </div> <div class="article-meta" tagx="article-meta" title="article-meta"><span class="pmcid" title="pmcid"> pmcid: <a href="http://www.ncbi.nlm.nih.gov/pubmed/7827223">7827223</a></span><span class="pmid" title="pmid"> pmid: <a href="http://www.ncbi.nlm.nih.gov/pubmed/33440797">33440797</a></span><span class="doi" title="doi"> doi: <a href="https://dx.doi.org/10.3390/s21020471">10.3390/s21020471</a></span><span class="publisher-id" title="publisher-id">sensors-21-00471</span><div class="article-categories" title="article-categories">
: <span class="subject" title="subject">Article</span></div> <div class="title-group" tagx="title-group" title="title-group"> <div class="article-title" title="article-title">
Analysis of UAV-Acquired Wetland Orthomosaics Using GIS, Computer Vision, Computational Topology and Deep Learning</div> </div> <div class="contrib-group" title="contrib-group"><span class="contrib" title="contrib"><span class="contrib-id" tagx="contrib-id" title="contrib-id">https://orcid.org/0000-0001-5693-5217</span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kentsch</span><span class="given-names" tagx="given-names" title="given-names">Sarah</span></span><a href="#af1-sensors-21-00471">1</a><a href="#af2-sensors-21-00471">2</a><a href="#c1-sensors-21-00471">*</a></span><span class="contrib" title="contrib"><span class="contrib-id" tagx="contrib-id" title="contrib-id">https://orcid.org/0000-0002-4417-1704</span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Cabezas</span><span class="given-names" tagx="given-names" title="given-names">Mariano</span></span><a href="#af3-sensors-21-00471">3</a></span><span class="contrib" title="contrib"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tomhave</span><span class="given-names" tagx="given-names" title="given-names">Luca</span></span><a href="#af2-sensors-21-00471">2</a></span><span class="contrib" title="contrib"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Groß</span><span class="given-names" tagx="given-names" title="given-names">Jens</span></span><a href="#af2-sensors-21-00471">2</a></span><span class="contrib" title="contrib"><span class="contrib-id" tagx="contrib-id" title="contrib-id">https://orcid.org/0000-0001-8636-9009</span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Burkhard</span><span class="given-names" tagx="given-names" title="given-names">Benjamin</span></span><a href="#af2-sensors-21-00471">2</a></span><span class="contrib" title="contrib"><span class="contrib-id" tagx="contrib-id" title="contrib-id">https://orcid.org/0000-0002-9748-7120</span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lopez Caceres</span><span class="given-names" tagx="given-names" title="given-names">Maximo Larry</span></span><a href="#af1-sensors-21-00471">1</a></span><span class="contrib" title="contrib"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Waki</span><span class="given-names" tagx="given-names" title="given-names">Katsushi</span></span><a href="#af4-sensors-21-00471">4</a></span><span class="contrib" title="contrib"><span class="contrib-id" tagx="contrib-id" title="contrib-id">https://orcid.org/0000-0003-4521-9113</span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Diez</span><span class="given-names" tagx="given-names" title="given-names">Yago</span></span><a href="#af4-sensors-21-00471">4</a><a href="#c1-sensors-21-00471">*</a></span></div><span class="citation_author_institution" id="af1-sensors-21-00471">[1], <span class="email" tagx="email" title="email">larry@tds1.tr.yamagata-u.ac.jp</span></span><span class="citation_author_institution" id="af2-sensors-21-00471">[2], <span class="email" tagx="email" title="email">luca.tomhave@kabelmail.de</span><span class="email" tagx="email" title="email">gross@phygeo.uni-hannover.de</span><span class="email" tagx="email" title="email">burkhard@phygeo.uni-hannover.de</span></span><span class="citation_author_institution" id="af3-sensors-21-00471">[3], <span class="email" tagx="email" title="email">mariano.cabezas@sydney.edu.au</span></span><span class="citation_author_institution" id="af4-sensors-21-00471">[4], <span class="email" tagx="email" title="email">waki@sci.kj.yamagata-u.ac.jp</span></span><div class="author-notes" title="author-notes"> <div class="corresp" title="corresp"><span class="label" tagx="label" title="label">*</span>Correspondence: <span class="email" tagx="email" title="email">sarah@tds1.tr.yamagata-u.ac.jp</span> (S.K.); <span class="email" tagx="email" title="email">yago@sci.kj.yamagata-u.ac.jp</span> (Y.D.)</div> </div><span class="pub-date-epub" title="pub-date-epub">epub: <span>2021-1-1</span></span><span class="pub-date-collection" title="pub-date-collection">collection: <span>2021-1</span></span><span class="volume" tagx="volume" title="volume">21</span><span class="issue" tagx="issue" title="issue">2</span><span class="elocation-id" tagx="elocation-id" title="elocation-id">471</span><span class="history" title="history"><span class="received" title="received">received: 2020-11-27</span><span class="accepted" title="accepted">accepted: 2021-1-07</span></span><div class="permissions"><span class="copyright" title="copyright">(C) , <span class="copyright-year" tagx="copyright-year" title="copyright-year">2021</span></span><span class="license" title="license"><span class="license-p" title="license-p">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<a href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</a>).</span></span></div> <div class="abstract" title="abstract"> <div class="abstract-title" title="abstract-title">
Abstract</div> <p>Invasive blueberry species endanger the sensitive environment of wetlands and protection laws call for management measures. Therefore, methods are needed to identify blueberry bushes, locate them, and characterise their distribution and properties with a minimum of disturbance. UAVs (Unmanned Aerial Vehicles) and image analysis have become important tools for classification and detection approaches. In this study, techniques, such as GIS (Geographical Information Systems) and deep learning, were combined in order to detect invasive blueberry species in wetland environments. Images that were collected by UAV were used to produce orthomosaics, which were analysed to produce maps of blueberry location, distribution, and spread in each study site, as well as bush height and area information. Deep learning networks were used with transfer learning and unfrozen weights in order to automatically detect blueberry bushes reaching True Positive Values (TPV) of 93.83% and an Overall Accuracy (OA) of 98.83%. A refinement of the result masks reached a Dice of 0.624. This study provides an efficient and effective methodology to study wetlands while using different techniques.</p> </div> <div class="kwd-group"> <div class="kwd" title="kwd">
ArcGIS</div> <div class="kwd" title="kwd">
big data</div> <div class="kwd" title="kwd">
blueberries</div> <div class="kwd" title="kwd">
deep learning</div> <div class="kwd" title="kwd">
image analysis</div> <div class="kwd" title="kwd">
orthomosaics</div> <div class="kwd" title="kwd">
segmentation refinement</div> <div class="kwd" title="kwd">
UAVs</div> </div> </div> </div> <div class="body" title="body"> <div class="intro" title="intro"> <div class="title" tagx="title" title="title">
1. Introduction</div> <p>Recent changes in global climate conditions influence species composition and accelerating the presence of invasive plant species in natural environments. Species that spread outside their native habitat and rapidly and effectively adapt to new environments are known as invasive species [<a href="#B1-sensors-21-00471">1</a>]. The spread of invasive species often benefits from ecosystem changes and habitat disturbances that weaken the natural species and open an ecological niche for invaders. Hence, invasive species can influence the biodiversity, thus limiting the growth of natural plant species due to a higher occurrence of an invasive species, which could lead to ecosystem degradation [<a href="#B2-sensors-21-00471">2</a>]. The fast adaption to multiple stress factors in environments could also lead to a replacement of native species and it may increase economic costs due to production losses in agriculture and forestry [<a href="#B3-sensors-21-00471">3</a>]. In Europe, 11% of the 12,000 identified species have caused damage to the economy, society, and the environment [<a href="#B4-sensors-21-00471">4</a>]. Reference [<a href="#B5-sensors-21-00471">5</a>] states that hundreds of invasive species find their pathways through horticulture, agriculture, etc., and the linearly increasing trend of invasive species numbers (from 1970 to 2007) indicates higher impacts of invasive species in the future. Reference [<a href="#B6-sensors-21-00471">6</a>] pointed out that not only invasive species have an impact on native plants, since several factors often interact with the environment that influence species distributions. In recent years, the need to precisely understand the ecological impacts of invasive species in ecosystems has become a key in designing and prioritizing natural resource management approaches [<a href="#B2-sensors-21-00471">2</a>], since the behaviour and impact of invasive species is still not well understood [<a href="#B3-sensors-21-00471">3</a>,<a href="#B7-sensors-21-00471">7</a>]. Furthermore, a high number of invasive plant are species spreading in natural environments, which increases the demand of management practices [<a href="#B5-sensors-21-00471">5</a>].</p> <p>In the past two decades, an explosive spread of North American blueberry hybrids (<i>Vaccinium corymbosum</i> x <i>angustifolium</i>) has been observed in several moors in the northern German geest area, endangering the natural development of these protected raised bog areas [<a href="#B8-sensors-21-00471">8</a>]. The starting point of the spread has been almost exclusively located at existing or former commercial blueberry plantations [<a href="#B9-sensors-21-00471">9</a>,<a href="#B10-sensors-21-00471">10</a>], which can be found near or in the immediate vicinity of bogs or former peat extraction areas, due to good soil and local climatic conditions. Most of the recipient habitats are pine forests and bogs in various stages of de- and regeneration. Because of these characteristics, the American Blueberry (<i>Vaccinium angustifolium</i> x <i>corymbosum</i>) has been classified as a potentially invasive neophyte by the <i>German Federal Agency for Nature Conservation</i> [<a href="#B11-sensors-21-00471">11</a>]. After the degradation of wetland areas due to anthropogenic activities, protection programs, called "Moorschutzprogramme", were established by the state government of Lower Saxony for the conservation and the development of rare animal and plant communities in these areas [<a href="#B12-sensors-21-00471">12</a>]. Furthermore, activities that could threaten the goals of the protection program are prohibited, which increases the difficulty of conducting relevant field studies [<a href="#B12-sensors-21-00471">12</a>]. However, maintenance and development measures are needed in order to rehabilitate protected and relatively sensitive wetland areas, into which the invasive blueberry species <i>Vaccinium corymbosum</i> x angustifolium has migrated. In 2011, 20 counties in Lower Saxony reported stands of spontaneously growing blueberry bushes [<a href="#B13-sensors-21-00471">13</a>]. The potential area that is occupied by spontaneously growing blueberry bushes can reach several square kilometres within a few years [<a href="#B14-sensors-21-00471">14</a>]. Previous studies, as presented in [<a href="#B10-sensors-21-00471">10</a>,<a href="#B14-sensors-21-00471">14</a>], used grids in the field in order to plot the distribution of blueberry bushes within wetlands. Both of the studies focused on sites near blueberry cultivation areas, as the biggest spread was found in close proximity to blueberry plantations [<a href="#B9-sensors-21-00471">9</a>]. Those studies show the limitations in the studied area and lack an overview. It is still unclear how far the blueberry bushes have already spread and in which areas they occur. In order to implement effective measures in these areas and minimise the disturbance of sensitive biotopes, it is necessary to locate the individual blueberry bushes as accurately and early as possible. In addition, the following questions arise: does a displacement of natural species occur and where should what measures be taken against a continuing invasion? According to [<a href="#B14-sensors-21-00471">14</a>,<a href="#B15-sensors-21-00471">15</a>], relatively simple counter measures can lead to good results and prevent further spread, especially when invasive blueberry bushes are identified early. Therefore, a suitable and non-invasive method for recording stock development and distribution is needed. A simple tool is needed to rapidly, cost-effectively, and precisely detect invasive species in wetlands to counteract their rapid reproduction. Wetlands are protected environments with limited ground accessibility making UAVs particularly appropriate for data collection. UAVs offer the possibility to cover large areas with high resolution images, and they have proved their usefulness in a variety of studies in agriculture [<a href="#B16-sensors-21-00471">16</a>,<a href="#B17-sensors-21-00471">17</a>] and forestry [<a href="#B18-sensors-21-00471">18</a>,<a href="#B19-sensors-21-00471">19</a>,<a href="#B20-sensors-21-00471">20</a>]. Still, UAV images present challenges like the pre-pocessing of the data. Large amounts of data need to be processed, labeled, and annotated by experts, which is usually time consuming, before the data can be further analysed. The use of deep-learning techniques reduces the amount of time that is needed to extract information from the data, which increases the benefits for several applications.</p> <p>Images that are acquired by UAVs can be analysed while using computer vision and GIS techniques. Important results can then be obtained by reducing the complexity contained in the images (using different image interpretation strategies) and the findings can be presented in elaborate visualisations [<a href="#B21-sensors-21-00471">21</a>]. Persistent homology, a tool of topological data analysis, can help to understand complex datasets by analysing their large scale geometric features [<a href="#B22-sensors-21-00471">22</a>]. In our study, we have used persistent homology to measure the spread of invasive species. Processing images and creating orthomosaics allow for a fast analysis of large amounts of data. Deep learning techniques additionally automatize classification and localisation processes, and make it possible to incorporate expert knowledge into the automatic image processing pipeline. This has the potential to increase the scale of the resulting studies to reach large regions that are significant in terms of country-level invasive species detection and management.</p> <p>In this study, the incorporation of all the mentioned techniques from remote sensing, GIS, computer vision, computational topology, and artificial intelligence allows for us to study invasive species on a large scale, with minimum disturbances and the incorporation of expert knowledge. To the best of our knowledge, this is the first study that includes different techniques and UAV gathered data to increase the understanding of an invasive blueberry species in wetlands. Furthermore, locating and studying small bushes in large areas and at the single-bush level was done for the first time. Therefore, UAV-supported methods offer an efficient possibility to discover individual young plants on a large scale and detect propagation hotspots at an early stage.</p> <p>The following objectives guided this study: </p><ul> <li><span class="label" tagx="label" title="label">(I)</span><p>To use UAV data in order to provide allometric statistics (height, area, and number) of invasive blueberry in large areas at bush level.</p> </li> <li><span class="label" tagx="label" title="label">(II)</span><p>To use clustering techniques and persistent homology to quantitatively and qualitatively assess the spread of blueberry invasions.</p> </li> <li><span class="label" tagx="label" title="label">(III)</span><p>To assess the potential of Deep learning to automatically segment blueberry bushes, initiating the possibility for even larger-scale studies.</p> </li> </ul> <p /> <div class="stateoftheart" title="sec"> <div class="title" tagx="title" title="title">
State of the Art</div> <p>In recent years, remote sensing techniques have been used in various natural environments with the goal of reducing the need for in situ measurements [<a href="#B23-sensors-21-00471">23</a>]. Low-cost data gathering, time saving, and larger study areas are the benefits. Furthermore, data can be directly used and processed within Geographical Information Systems (GIS) [<a href="#B23-sensors-21-00471">23</a>]. This has been done successfully, for environmental studies [<a href="#B24-sensors-21-00471">24</a>,<a href="#B25-sensors-21-00471">25</a>,<a href="#B26-sensors-21-00471">26</a>]. Closely related to the current work, Reference [<a href="#B27-sensors-21-00471">27</a>] proposed using GIS as a synthesising tool in invasive species management approaches. Reference [<a href="#B28-sensors-21-00471">28</a>] used satellite images of 1992 and 2002 in order to identify stress indicators and change detection in a wetland in Sri Lanka to quantify the conditions of the complex. The authors state that the inventory, mapping, and monitoring are needed to understand interactions in the ecosystem. Classification with the Maximum Likelihood Algorithm were performed, mapping and spatial analysis were used, and finally refined and verified with ground data. Their approach ([<a href="#B28-sensors-21-00471">28</a>]) reached 86% accuracy and provided detailed analysis. GIS in combination with remote sensing data was found to be an effective methodology for investigating wetlands. Reference [<a href="#B29-sensors-21-00471">29</a>] evaluated vegetation change detection while using the NDVI of remote sensing data and applied GIS in order to visualise the results. Landsat and Shuttle Radar Topography Missions were used to capture the Vellore District. Image interpretations were carried out using ERGDAS IMAGINE software in order to classify and detect changes in the vegetation. The differences in the NDVI values were used to analyse data sets of the years 2001 to 2006. The study provided information about the lowest decrease in the forest area by 6%, while agriculture land increased the most by 19%.</p> <p>In comparison to satellite images UAV images provide a higher resolution and appear to be more suitable for wetland investigations, especially when focusing on invasive species. Higher resolution images allow for higher accuracies of image interpretations and feature extractions [<a href="#B30-sensors-21-00471">30</a>]. Several studies using UAVs in wetlands have already been carried out [<a href="#B31-sensors-21-00471">31</a>,<a href="#B32-sensors-21-00471">32</a>,<a href="#B33-sensors-21-00471">33</a>,<a href="#B34-sensors-21-00471">34</a>]. Reference [<a href="#B34-sensors-21-00471">34</a>] developed a method for detecting and mapping invasive species with UAVs. The authors acknowledged UAVs as suitable for monitoring eradication efforts in wetlands. Reference [<a href="#B33-sensors-21-00471">33</a>] realized the higher efficiency in gathering valuable and accurate information in comparison to field studies, when using UAVs and computer vision techniques to enhance classifications and health assessments in wetlands. Gandhi et al. [<a href="#B31-sensors-21-00471">31</a>] used UAV imagery for detecting invasive species and mapping their distribution and spread. This study also compared data from two years (2009 and 2011) and detected an increase of 19.07%, which was confirmed by field studies with a total agreement of 94% and shows the suitability of UAV imaging for this kind of application. Reference [<a href="#B31-sensors-21-00471">31</a>] lanalysed the spread of <i>Spartina alterniflora</i> in Beihai in the years 2009 and 2011, using high resolution images acquired by UAVs. They captured images at a flight height of 800 m, generated orthomosiacs, performed multi-resolution segmentation by grouping homogenous pixels, and classified them. The target species was extracted by their pixel values. In a final step the accuracy was assessed and verified with field data by comparing three sample plots (a total of 166 samples) with the image results. A total accuracy of 94.0% could be achieved and, hence, provided information regarding an increasing spread of 19.07% from 2009 to 2011. The total infected area was, in 2011, 357.2 ha. Moreover, the image analysis provided the opportunity to identify areas with different levels of densities. Reference [<a href="#B35-sensors-21-00471">35</a>] collected UAV images of <i>Harrisia pomanensis</i> in the Limpopo province of South Africa. An area of 87 ha was captured by images that were taken at a height of 800 to 817 m. Orthomosaics generated with Agisoft Photoscan and pixel as well as object-based classifiers were used. The classification results of supervised and unsupervised classifiers were assessed. The supervised classification outperformed the unclassified one, and the object-based approach outperformed the pixel-based one. The best accuracy achieved was 86.1%.</p> <p>Given the sizes of the data sets used and the need to detect and classify parts of the images that only trained experts can confidently tell apart the use of deep learning in problems that are closely related to the current work is of common use. For example, a recent study [<a href="#B36-sensors-21-00471">36</a>] used CNN (convolutional neutral network) in order to classify images from wetlands in an area of 700 km<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. They used a fully trained and fine-tuned CNN with a limited amount of data. A comparison of the CNN with random forest was performed to evaluate the capacity and classification accuracies of CNNs. Canadian wetlands were captured with two RapidEye images with 5 m resolution in 2015. The validation data were sampled in 2015 and 2016 and four wetland classes were identified using 1000 samples. The network was trained with patches and 30,000 iterations and then tested in a second step. The CNN outperformed the random forests and an overall accuracy of 94.82% was achieved, varying between 76.65% and 98.74%. Deep convolutional neural networks were also used by [<a href="#B37-sensors-21-00471">37</a>] in order to classify AUV-acquired wetland images. The 677 m × 518 m study area was located in Southern Florida. The authors used processed orthomosaics and multi-view images and then compared them with the performances of random forests and support vector machines. Image segmentation was done with Trimble’s eCognition by first segmenting objects, then extracting features, and finally training a classifier. The results of the study show the advantages of deep CNN, reaching an accuracy of 82.02%, when multi-view images were used and with lower accuracy when orthomosaics were used (71.69%). A similar approach was used in [<a href="#B38-sensors-21-00471">38</a>]. 3800 images of the Brazilian national forest (Kaggle dataset) were used in order to identify <i>hydrangea</i> in the images. The dataset contained two-thirds of images, including the invasive species, a smaller fraction, where the invasive species appeared only in parts of the images, and a third small fraction that included no plants at all. The authors used three models: VGGNet, DenseNet, and Inception, which were pre-trained with ImageNet. Data augmentation was used and accuracies of 97.6% were reached.</p> </div> </div> <div class="2.materialsandmethods" title="sec"> <div class="title" tagx="title" title="title">
2. Materials and Methods</div> <div class="2.1.studyarea" title="sec"> <div class="title" tagx="title" title="title">
2.1. Study Area</div> <p>The study area "Lichtenmoor" is located in a wetland region about 60 km northwest of Hanover in Lower Saxony, Germany (52°43<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mo_UNKNOWN">
′</div> </div> </div></div></span>06.2<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
″</div> </div> </div> </div></div></span> N 9°20<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mo_UNKNOWN">
′</div> </div> </div></div></span>41.5<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
″</div> </div> </div> </div></div></span> E) (<a href="#sensors-21-00471-f001">Figure 1</a>).The total size of the moor area is 38 km<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> [<a href="#B39-sensors-21-00471">39</a>]. Post industrial peat cutting characterises the central area of the studied wetland. As a subsequent use, some former peat cutting areas have been rewetted with the aim of regenerating raised bogs. In the surrounding area, parts of the Lichtenmoor have been designated as nature reserves. Former hand peat cutting sites are located at the edges and in parts of the nature reserves. Agricultural areas dominate the remaining areas, mostly grassland, dry to moist moorland forests, scrubby heather and moorland degeneration stages, pioneer stages of moorland rewetting, and peat extraction areas under cultivation. The case study area covers a total area of 62 ha and it is located in the central part of the Lichtenmoor region. To the northeast, it borders a pine plantation, while at its southwest border current peat extraction areas are located. Blueberry plantations can be found throughout the Lichtenmoor, especially on the outskirts of the localities Lichtenhorst, Heemsen, Sonnenborstel, and Steimbke.</p> </div> <div class="2.2.characteristicsoftheblueberryspecies" title="sec"> <div class="title" tagx="title" title="title">
2.2. Characteristics of the Blueberry Species</div> <p>Blueberries have been cultivated in commercial plantations in Lower Saxony since the early 1930’s [<a href="#B14-sensors-21-00471">14</a>]. Since then, the area under cultivation has steadily increased. In 2005, the area with blueberry cultivation in Lower Saxony was approximately 1400 hectares [<a href="#B13-sensors-21-00471">13</a>]. In nature, blueberries are mainly distributed by birds and small mammals, who spread the seeds. Once established, plants can spread in a vicinity by clonal growth and the high regeneration potential of blueberries favours a strong spread [<a href="#B10-sensors-21-00471">10</a>]. The species prefers acidic locations, such as pine forests or wetlands. Especially, raised bogs in their degeneration stage provide ideal habitat conditions for invasive blueberries [<a href="#B14-sensors-21-00471">14</a>]. Thus, blueberries are growing increasingly wild in neighbouring areas. References [<a href="#B9-sensors-21-00471">9</a>,<a href="#B14-sensors-21-00471">14</a>] found a correlation between the density of blueberries and the distance to blueberry plantations; a maximum distance of 1700 m was recorded. Near cultivated areas, the feral blueberries form dense shrub stands with height of up to 2–3 m and have a ground coverage of up to &amp;gt;60%. With increasing distance, the degree of coverage decreases rapidly [<a href="#B8-sensors-21-00471">8</a>,<a href="#B9-sensors-21-00471">9</a>,<a href="#B13-sensors-21-00471">13</a>]. Since these studies were already conducted in the last millennium, a larger distribution must be expected today. Reference [<a href="#B10-sensors-21-00471">10</a>] describes a distribution of blueberry bushes over 4 ha in the "Krähenmoor", where the maximum distance to the plantation was identified at 100 m. Blueberry bushes are low and can reach a height of 60 cm, but, occasionally, tall species can be found with a height of 3 m [<a href="#B10-sensors-21-00471">10</a>]. In the course of the increasing growth and dense shrub structures, other ground vegetation is displaced, since it cannot exist under the shade of blueberries. Other presumed effects of blueberry cultivation are reduced evaporation rates and the influence on nutrient cycles in wetlands, which, in turn, can have an impact on existing plant species. Therefore, human interventions are necessary to protect the sensitive rare structures and characteristic plants of wetlands [<a href="#B10-sensors-21-00471">10</a>].</p> </div> <div class="2.3.datacollectionandpre-processing" title="sec"> <div class="title" tagx="title" title="title">
2.3. Data Collection and Pre-Processing</div> <p>Image collection was performed by using a DJI phantom 4 UAV in autumn 2018, because of the seasonal red colouring of blueberry leaves, which makes them easily detectable (<a href="#sensors-21-00471-f002">Figure 2</a>). For sites B1 to B4, 490 to 584 images were collected, while 1346 images were taken for B6. The flight height was 50 m and front and side overlaps of 80% were chosen. These images were then processed while using the Metashape software [<a href="#B40-sensors-21-00471">40</a>] to align images in order to produce one orthomosaic and DEM (Digital Elevation Model) for each site (<a href="#sensors-21-00471-f001">Figure 1</a>). It should be mentioned that an overlap between the sites B1 to B4 was chosen, so the east and west borders of the orthomosaics B1 to B4 are overlapping. All of the obtained orthomosaics were annotated while using the open source image manipulation software GIMP [<a href="#B41-sensors-21-00471">41</a>]. For three of them (B1, B2, and B3), the whole orthomosaic was annotated and each pixel was given one of the following six labels: blueberries, trees, yellow bushes, soil, water, and dead trees (<a href="#sensors-21-00471-f001">Figure 1</a>). The class trees contains pine trees (<i>Pinus sylvestris</i>), the class yellow bushes contains shrubby birches (predominantly <i>Betula pubescens</i>, secondarily <i>Betula pendula</i>). Binary layers for each of the six classes were created for each of the three orthomosaics while using the pixel-level labels. These annotations were based on colour, shape, and context information contained in the orthomosaics. In the last two orthomosaics (B4 and B6), only blueberry bushes were annotated.</p> <p>In order to train deep learning models to detect blueberry bushes orthomosaics annotated with all of the aforementioned labels were needed. Therefore, only B1 to B3 were used in the deep learning section of this study. These three orthomosaics, as well as the corresponding annotated binary layers were divided into axis-parallel patches of side length = 100 (hereafter "patch size"). This value was determined by taking the sizes of the blueberry bushes in the images, which ranged from 20 to 100 pixels in radius, into account. The classes in each patch were stored in a separate <i>label</i> list. In general, patches contained more than one class and, therefore, our problem can be defined as a multi-label patch classification problem.</p> <div class="2.3.1.dataprocessingusingarcgis" title="sec"> <div class="title" tagx="title" title="title">
2.3.1. Data Processing Using Arcgis</div> <p>This section deals with data processing performed with ArcGIS pro 2.4.1 and python in order to identify parts of the orthomosaic containing blueberry bushes, in order to visualize them and analyse their characteristics. ArcGIS is a Geographic Information System software that visualises and comprehends geographic data. The software provides over 1000 tools to analyse real world data, including UAV-acquired images. The mapping options allow to visualise the gathered data within the correct location in an eligible base map. The primary purpose of this study was to provide information about the location and distribution of invasive blueberry species and map them for management.</p> <p>In this context, the positions of the blueberry bushes in the five orthomosaics were digitised by hand as point data in an ArcGIS shapefile and several analytical tools were then used (<a href="#sensors-21-00471-f002">Figure 2</a>). The <i>kernel density</i> tool functions were used to calculate the magnitude-per-unit area from the blueberry points. Smaller search radiuses were used to show a detailed density raster. The tool <i>integrate</i> was used to group blueberry bushes that fall into a specified distance, as specified distance, 3 and 6 m were used. With the tool <i>collect event</i>, the number of points which were integrated before, were summarized in a new layer. Those steps were necessary to perform an <i>optimized hotspot analysis</i> of the blueberry abundance with the blueberry point shapefile. The hotspot analysis identifies the significant difference between the neighbourhood of a feature in comparison to the extent of the respective study area. Is the value of a feature significantly higher, it is considered to be a hotspot and the tool provides a feature map with three levels of confidence (90%, 95%, and 99%). As input for the hot spot analysis, the created layer of the tool <i>collect events</i> was used and analysis field counts were chosen. Furthermore, it also indicates the significantly lower features.</p> <p>On the basis of the annotation made for all orthomosaics, several simple python codes and ArcGIS were used to perform image analysis. Pixels were counted for all orthomosaics, as well as all annotated layers. The number of black pixels in the annotated layers were specifically counted in order to obtain the percentage and area in m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> per class. Additionally, the overall area presented in the orthomosaics was calculated in hectares. Because the focus of this study was on the blueberry bushes, several statistical values were generated: the number of blueberry bushes was counted and the number of blueberry bushes per ha was calculated for each orthomosaic. Additionally, the total area, as well as the area per blueberry bush, were computed in m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. Furthermore, the proportion of blueberry bushes in relation to the vegetation was calculated in %. Finally, height values were computed on the basis of DEMs, annotations of the blueberry bushes, and annotations of ground points per site. Ground points were annotated close to blueberry bushes in order to increase the accuracy of the computed height. Maximum height values were estimated in a first analysis and the median height in a second analysis to evaluate the results.</p> </div> </div> <div class="2.4.persistenthomology" title="sec"> <div class="title" tagx="title" title="title">
2.4. Persistent Homology</div> <p>Persistent homology provides topological information of complex datasets [<a href="#B42-sensors-21-00471">42</a>] at different spatial resolutions. This information deals with the connectivity of nearby points and it can be computed in different dimensions. For the purpose of this study, we worked with 0-D persistent homology (usually expressed in the form of H0 diagrams). H0 homology can be seen as growing disk at uniform radius-increase speed around pre-defined data points. In order to use this tool, we first discredited the manually annotated blueberry regions by uniformly sampling them. Subsequently, the radius around each sample point was increased to grow blueberry bush regions. When two blueberry regions were merged because of the expansion, one of the regions was considered to be dead because it was absorbed by the other region. As time passed, the number of connected blueberry regions decreased, and finally all of the regions were connected in one region.</p> <p>The H0 diagram shows the change in the connectivity of the blueberry bushes by plotting the time/radius when blueberry regions get connected. False regions that were produced by our sampling of the annotated regions were discarded and only those parts of the diagrams that were obtained after all sampling points in each region had been joined together were considered. Based on this outcome, the radius was calculated until 1%, 10%, 50%, and 90% of the blueberry regions were connected and plotted. The diagram will vary greatly, depending on the number and position of blueberry bushes in the input image.</p> </div> <div class="2.5.deeplearningtechniques" title="sec"> <div class="title" tagx="title" title="title">
2.5. Deep Learning Techniques</div> <p>Deep learning is a trending field of machine learning that focuses on fitting large models with millions of parameters for a variety of tasks, such as image classification and segmentation. These approaches have been rapidly gaining attention in computer vision tasks, due to their recently increased accuracy. Deep learning models commonly learn from examples in a supervised manner. First, an <i>architecture</i> or a graph of connected nodes is defined. These nodes are often grouped in <i>layers</i> that perform a specific operation, and the combination of a large number of layers is referred to as a <i>deep neural network</i> (<b>DNN</b>).The typology of the nodes, the number of nodes per layer and the connections between them determine the behaviour of the network. In general, two main types of nodes are used: linear nodes, expressed as matrix multiplications and nodes that introduce non-linear functions (such as the sigmoid function). The weights in linear nodes are usually initialised with random values following a specific distribution. Afterwards, the network is given samples of the data, known as <i>training samples</i>, which contain instances of the problem (i.e., image intensities) with their corresponding solutions (i.e., labels). These samples are iteratively run through the network in order to evaluate its current accuracy and the weights are updated following an optimization process.</p> <p>In this study, DNNs were used to locate and identify the six classes that are defined in <a href="#sec2dot3-sensors-21-00471">Section 2.3</a>, with a focus set on the blueberry class. The basis for this deep learning approach is described in previous studies [<a href="#B20-sensors-21-00471">20</a>,<a href="#B43-sensors-21-00471">43</a>], which led to the use of the algorithms that are described in this section.</p> <p>Our approach is based on a patch classification model that uses the patches of 100 × 100 pixels described in <a href="#sec2dot3-sensors-21-00471">Section 2.3</a>. A patch of orthomosaic B1 and B3 covered; therefore, 700 cm × 700 cm and a patch of orthomosaic B2 500 cm × 500 cm. For each patch, a list containing the class labels was created from the binary maps for each class. This classification is usually referred as multi-label, since each input patch might contain different labels (i.e., a part of the patch may contain soil, while other parts of the same patch could also contain bushes or blueberries).</p> <p>Deep neural networks for classification have two major components: a feature extraction stage and a prediction stage. At the first stage, convolutional operators are trained in order to extract salient and meaningful features (such as texture) while at the second stage these features are used to predict the final labels for the given input patch or image. In order to train general and robust feature extractors, a large pool of heterogeneous images with different properties (lightning, colour, view, etc.) is needed to capture all of the possible image variabilities. However, as proven by our previous work [<a href="#B20-sensors-21-00471">20</a>,<a href="#B43-sensors-21-00471">43</a>], transfer learning is a useful tool for image analysis applications, where the training dataset is too small to properly train these feature extractors from scratch.</p> <p>In our case, only three different orthomosaics are available; hence, we decided to use transfer learning by loading a pre-trained ResNet50 architecture with weights from ImageNet, due to its accuracy and reduced training time. ImageNet is one of the largest image databases for image classification research, with more than 80,000 labels and at least 1000 images for each label.</p> <p>In order to perform the evaluation of the proposed model, two of the three orthomosaics were used for training and validation and the third one was used for testing. This cross-validation strategy is usually referred to as a leave-one-out strategy. All of the orthomosaics were used once for testing, training, and validation by rotating them for each experiment. Patches from the testing orthomosaic were not included for training or validation to avoid data leakage during training.</p> <p>Two main approaches were used in order to obtain a higher detection rate for the blueberry class: </p><ul> <li> <p>Data augmentation is a commonly used strategy in deep learning and it can increase the size of the training datasets without the need to collect new data. In this case, data augmentation was used to generate new synthetic patches of the blueberry class, which was the less frequent class (see <a href="#sec3dot2-sensors-21-00471">Section 3.2</a> for details). Six image transformations to augment the data were used: up/down and left/right flips; small central rotations with a random angle, in order to simulate different perspectives of the bushes; Gaussian blurring of the images, which simulates blurring due to the movement of the UAV; linear and small contrast changes, which can represent different light and shadow conditions and localised elastic deformations. In order to implement this transformations we used the "imgaug" library [<a href="#B44-sensors-21-00471">44</a>].</p> </li> <li> <p>Loss functions are used to compute the accuracy of the network and update their parameters. By giving different weights to different classes, their importance can be changed during training. In this study, two loss functions were used; the first function checks if a patch contains a blueberry or not, while the second one checks the fraction of blueberry pixels inside the patch. The optimal training settings followed the ones that were used in our previous study [<a href="#B43-sensors-21-00471">43</a>].</p> </li> </ul> <p /> <p>We considered labels for all the patches used and the relation between (1) predicted values resulting from our algorithm and (2) real values as stated in the manually-annotated ground truth in order to assess the predictive power of our algorithms.</p> <p>We then broke all of the patches into the usual classification categories of: </p><ul> <li> <p><b>True Positives</b> or TP, predicted to contain the blueberry class and also marked in the ground truth as containing them.</p> </li> <li> <p><b>False Positives</b> or FP, predicted to contain the blueberry class but NOT marked as such in the ground truth. These patches correspond to over-prediction errors where the algorithm "sees" the blueberry class when it is not really there.</p> </li> <li> <p><b>True Negatives</b> or TN, not containing the blueberry class in the prediction or in the ground truth.</p> </li> <li> <p><b>False Negatives</b> or FN, not predicted to contain blueberries, but actually being marked as containing them in the ground truth. These patches correspond to under-prediction errors where existing blueberry instances are missed by the algorithm.</p> </li> </ul> <p /> <p>We used the two following metrics (True Positive Rate or Sensitivity and Accuracy) in order to summarize the occurrences of the four categories. </p><div class="disp-formula" title="disp-formula"><span class="label" tagx="label" title="label">(1)</span><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> <div class="mi_UNKNOWN">
R</div> <div class="mo_UNKNOWN">
=</div> <div class="mi_UNKNOWN">
S</div> <div class="mi_UNKNOWN">
E</div> <div class="mi_UNKNOWN">
N</div> <div class="mi_UNKNOWN">
S</div> <div class="mo_UNKNOWN">
=</div> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
F</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> <div class="mspace_UNKNOWN" /> <div class="mi_UNKNOWN">
A</div> <div class="mi_UNKNOWN">
C</div> <div class="mi_UNKNOWN">
C</div> <div class="mo_UNKNOWN">
=</div> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
N</div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
F</div> <div class="mi_UNKNOWN">
P</div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
F</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> </div> </div> </div> </div> </div></div></div> <p /> <p>Finally, we modified the algorithm to present the results in a way that was more usable for end-users. The 100 × 100 patches used for prediction managed to capture most of the occurrences of the Blueberry class (see <a href="#sec3dot2-sensors-21-00471">Section 3.2</a> for details). However, these rather large patches also included large areas that actually contained no blueberries. While expert users could easily use these results as a starting point in order to quickly identify the exact location of blueberry bushes, we felt that refining our prediction using smaller patches would make their work faster, while also providing clearer information for non-expert users. Consequently, we divided each of the predicted 100 × 100 patches into 16 25 × 25 patches, re-sampled each of these newly-made smaller patches to the image size that is used by our DNN and re-classified them. This resulted in a refined result made up of 25 × 25 patches. This process had the disadvantage that, if errors were made, some of the correctly predicted blueberry pixels might be lost. In order to evaluate this issue, we considered the <i>TP</i>, <i>FP</i>, <i>TN</i>, and <i>FP</i> status of each pixel in each patch and measured the percentage of positive pixels that were covered by our predicted patches as well as the Dice coefficient that gave us an indication of the relative weight of blueberry pixels inside of our predicted patches: </p><div class="disp-formula" title="disp-formula"><span class="label" tagx="label" title="label">(2)</span><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
D</div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
c</div> <div class="mi_UNKNOWN">
e</div> <div class="mo_UNKNOWN">
=</div> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mn_UNKNOWN">
2</div> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> </div> <div class="mrow_UNKNOWN"> <div class="mn_UNKNOWN">
2</div> <div class="mi_UNKNOWN">
T</div> <div class="mi_UNKNOWN">
P</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
F</div> <div class="mi_UNKNOWN">
P</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
F</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> </div> </div> </div> </div></div></div> <p /> </div> </div> <div class="results" title="results"> <div class="title" tagx="title" title="title">
3. Results</div> <p>This section is divided in two parts: the first part of the analysis focused on the manual annotations of the wetland vegetation and, most specifically, of the blueberry bushes. GIS, computer vision, and persistent homology were used to describe and quantify the characteristics of the blueberry invasion in all of our test sites. In the second part of this section, the results of Deep learning techniques are presented. In this case, our goal was to assess to what extent these technologies can be used to automatically generate the annotations that were used in the first part to characterise the invasion. The general workflow can be seen in <a href="#sensors-21-00471-f003">Figure 3</a>.</p> <div class="3.1.analysisoftheblueberryinvasion" title="sec"> <div class="title" tagx="title" title="title">
3.1. Analysis of the Blueberry Invasion</div> <p>In this part of the study, we focused on characterising and measuring the blueberry invasion of the wetland.</p> <div class="3.1.1.quantitativeanalysisofblueberrybushes" title="sec"> <div class="title" tagx="title" title="title">
3.1.1. Quantitative Analysis of Blueberry Bushes</div> <p>The distribution of the classes in the images (blueberries, trees, yellow bushes, soil, water, and dead trees, see <a href="#sec2dot3-sensors-21-00471">Section 2.3</a>) was analysed and the state of the invasion was assessed by gathering information regarding the areas of the sites, the numbers of blueberry bushes, and the average area per bush.</p> <p>One important aspect was to calculate the area of blueberry bushes within the orthomosaics. The area covered by the orthomosaics varied between 10.6 to 12.5 ha, only B6 was larger with 15.5 ha (<a href="#sensors-21-00471-t001">Table 1</a>). Together with the annotations made for B1 to B3 the area of each class was calculated (<a href="#sensors-21-00471-f004">Figure 4</a>). As can be seen in the orthomosaic (<a href="#sensors-21-00471-f001">Figure 1</a>) the main part of the image represented soils. This was validated by the area calculations: with 76% of the orthomosaic B2 and 89% of B3, soil represents the highest values of all classes. The second smaller pie shows the living vegetation varying between 4.7% in B1 to 18.6% in B2. Out of the living vegetation, 8.2% (B2), 15.0% (B3), and 21.1% (B1) are blueberry bushes. In most of the orthomosaics blueberries were the least frequent class (with 1 to 1.5%).</p> <p>The number of blueberry bushes varied from 235 in orthomosaic B6 to 687 in B2 (<a href="#sensors-21-00471-t001">Table 1</a>). The site areas of orthomosaic B1, B3 and B4 were similar, while orthomosaic B6 is the largest site containing the least number of blueberry bushes and orthomosaic B2 contains the greatest number of blueberry bushes in the smallest area. The ratio could be confirmed by calculating the blueberry bushes per ha (<a href="#sensors-21-00471-t001">Table 1</a>). In another step, annotations were used in order to calculate the total area covered by blueberry bushes. In orthomosaic B6, an area of 278.07 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> was covered by blueberry bushes, which represents the smallest area and it resulted in an area of 1.18 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> per blueberry bush. The largest area was covered by blueberry bushes in B2 with 1885.51 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. The average size of the bushes were similar for B2 and B3. In site B1 the average size of blueberry bushes was the highest with 3.55 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>, while the covered area was third lowest with 1331.41 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>.</p> <p>Because the covered area and the average size of the bushes could be calculated, the next point of interest was the area and height per blueberry bush (<a href="#sensors-21-00471-f005">Figure 5</a>). Bushes were grouped into six to smaller than 10 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> and over 10 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> because the percentage of blueberries decreased towards larger cover areas. B1 and B2 had approximately 30 bushes between 6 and 8 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>, which was the maximum of all sites. The mean areas were computed for all orthomosaics, indicating that B1 had a high number of large bushes with a mean area of 3.57 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. The smallest blueberry bushes could be found in orthomosaic B6 indicated a mean value of 1.18 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. In general, most of the blueberry bushes showed areas of up to 2 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>, a lower amount distributed between 2 and 4 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> and the lowest numbers distributed in areas greater than 4 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. B1 was an exception, with around 10% per class over 4 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. The highest areas calculated range between 17 to 25 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>, with B1 containing four bushes in that range and 27 with areas above 10 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>. The lowest areas were found to be less than 10 cm<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> for B1/B4 and approximately 15 cm<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> for all other orthomosaics.</p> <p>A similar distribution can be seen in <a href="#sensors-21-00471-f005">Figure 5</a>, where the number of blueberry bushes were plotted against the height. Classes were chosen for each 0.5 m starting with 0 m up to lower than 3.5 m and more than 3.5 m. This distribution was chosen due to the characteristics of shallow blueberry bushes that reach 60 cm and tall species that reach 3 m. Regarding the maximum height, no height was computed for 2.3% (B1) up to 15.5% (B6) while the numbers were higher when the median height was considered (11.0% for B1 up to 35.2% for B6). In general, the median height values were higher for the classes 0 m and 0.5 m in comparison to the maximum height, while the values are lower from 0.5 m.The lowest height values started from 0.01 m (B6), 0.03 m (B1), 0.07 m (B3/4), and 0.1 m (B2) for both max. and median height. In general, the maximum and the median height distribution of the orthomosaics was similar. Almost all of the blueberry bushes in orthomosaic B6 were within the class &amp;lt; 0.5 (83.3%). In B1 the number of blueberry bushes in this same class was 79% and 15.2% was between 0.5 and &amp;lt;1 m, which was similar to B6. Orthomosaic B2 to B4 showed a Poisson distribution, whereby B2 had the highest number in <span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mn_UNKNOWN">
1</div> <div class="mo_UNKNOWN">
&amp;lt;</div> <div class="mn_UNKNOWN">
1.5</div> </div> </div></div></span> m with 21.2 m, while 41.6 of the blueberry bushes in B4 had the highest value in &amp;lt;0.5 m. Furthermore, in B2 and B3, more than 50% of the blueberry bushes reached heights between 1 m and 3.5 m (57% and 57.7%).It has to be considered that the area was calculated on the shapefiles in ArcGIS, while our developed python code was used in order to calculate the height of the blueberry bushes. Because the input for the code was the annotations of the blueberry bushes that were stored as a PNG file, those bushes that were close together were grouped. Therefore, the height values were not always calculated for an individual bush, which resulted in a different number of blueberry bushes per site: 309 (B1), 519 (B2), 461 (B3), 394 (B4), and 219 (B6).</p> </div> <div class="3.1.2.analysisofspreadpatterns" title="sec"> <div class="title" tagx="title" title="title">
3.1.2. Analysis of Spread Patterns</div> <p>In a second step of our quantitative analysis of the blueberry invasion, the concentration, density, and spread patterns were examined. GIS and persistent homology were used to assess these issues. Characterisations of concentrations and densities can indicate the number of blueberry bushes within a given region of the orthomosaic, which exceeds a simple location because the distribution of the bushes can be analysed precisely. Clustering bushes and mapping densities further increase the understanding of the distribution. Together with the persistent homology and hotspot analysis, the spread can be defined for all orthomosaics, which helps to characterise the invasion.</p> <p>The first step was to cluster blueberry bushes by using specified distances, of which 3 and 6 m were chosen, due to the calculated area of the blueberry bushes. The average diameter was considered to be 2 m for the different sites, and therefore a diameter of 3 m was found to be appropriate to especially group blueberry bushes that were close to each other. The results of both distances were compared and they are listed in <a href="#sensors-21-00471-t002">Table 2</a>. When blueberry bushes were located in a range of 3 m, they were clustered with the following results. From orthomosaic B3 to B1, 35.51% to 39.87% were clustered. The highest number of clustered bushes were 33 in B3, followed by 25 in B2 and 10 in B1. In comparison to B1 to B3, B4 and B6 had around 28.3 % clusters with three and more blueberry bushes. The highest number within a cluster was nine for B4 and 13 for B6. After increasing the range to 6 m, the number of blueberry bushes clustered in the group 3 or more bushes increased to 69.57%, which is more than 30 percentage points. B1, B3, and B4 had a similar increase of around 15 percentage points and reached 56.63 % in B1, 50.43% in B3 and 44.35 in B6. With less than 10 percentage points, 37.68 % of the blueberry bushes were grouped together with more than three bushes.</p> <p>Based on the point shapefiles of the blueberry bushes, density maps were generated to see how the bushes were distributed within the map. <a href="#sensors-21-00471-f006">Figure 6</a> provides three examples of the orthomosaics B1 to B3. Areas with a high density are marked in red and low densities in dark green. Orthomosaic B1 has one large density spot in the northwestern part of the map, while the southeast direction the density decreases with only single or paired bushes. Orthomosaic B2 shows four density spots. Two smaller ones were located in the northwest, a larger spot is in the middle of the orthomosaic and a final one in the southeast. The space between the middle and southeast spot is covered by blueberry bushes, which was similar to the distribution of B3. In orthomosaic B4, nearly the whole area is covered with green to reddish colours. There are three dense spots in the northwest, two spots in the middle and one in the southeast. In comparison to B2 and B3, the spots are smaller. Orthomosaic B6 covers a larger area than all other orthomosaics, but only three density spots could be identified in the middle of the orthomosaic. There were smaller groups of blueberry bushes along the borders of the orthomosaic, and single ones are distributed close to the groups of bushes.</p> <p>Another analysis focused on the point analysis to generate a map of hotspot areas in order to analyse the spread of the blueberry species. The point analysis used the manually marked blueberry bushes to identify where the proximity of the bushes was significantly different (hot and cold), and to quantify those that were not identified as significantly different. In B1, two 90% confidence hotspots were found in the north. 21 clusters were identified to be 90% significantly different from the study area. The hotspots in B2 were concentrated in the south-easternmost part of the orthomosaic. 26 clusters (out of 220) were significantly different to the study area with a confidence interval of 99%. These points contained all of the bushes located in the south-easternmost part of the orthomosaic. In B3 16 out of the 214 clusters fell into the 99% confidence interval, all located in the south-east of the orthomosaic. The same characteristic was found in B4. 23 clusters out of 248 were found to be significant with a 99% confidence and seven points with 90% to 95% confidence. B4 was the only orthomosaic containing two points considered to be cold spots with 90% confidence in the centre of the orthomosaic.</p> <p>Finally, the persistent homology was performed, as described in <a href="#sec2dot3dot1-sensors-21-00471">Section 2.3.1</a>. The radius was plotted against the fused region, as can be seen in <a href="#sensors-21-00471-f007">Figure 7</a>. The orthomosaics B2, B3, and B4 show a similar trend, while B1 and B6 also follow a different, but similar, trend to each other. B2 is the first orthomosaic, where 1% of the blueberry bushes were fused with a radius of 386 and B1 needed the largest radius with a value of 497. In all orthomosaics the radius needed to fuse up to 10% of the blueberry bushes is similar with values between 415 and 557. There is a small gap of approximately 150 between B3 (945), B6 (998), B1 (824), B2 (768), and B4 (831), when 50% of the blueberry bushes were fused. The radius needed to fuse 90% for B1 and B6 are 3279 and 3611, while, for B2 to B4, it is 1610 to 1709.</p> </div> </div> <div class="3.2.deeplearningresults" title="sec"> <div class="title" tagx="title" title="title">
3.2. Deep Learning Results</div> <p>In this section, we describe the usefulness of deep learning techniques in order to automatically determine the location of blueberry bushes in our data. As stated in <a href="#sec2dot5-sensors-21-00471">Section 2.5</a>, a widely used network (ResNet50) was chosen and two main aspects were studied: how the data balance affects the final classification results and whether using transfer learning resulted in improved results. Several experiments were presented in a previous study [<a href="#B43-sensors-21-00471">43</a>]; however, we will only focus on the optimal results for this current study.</p> <p>Regarding transfer learning, <i>unfrozen</i> ImageNet [<a href="#B45-sensors-21-00471">45</a>] weights were considered to initialise the network. When the model weights are <i>unfrozen</i>, all of the layers are normally trained and, thus, all the weights are updated. Regarding the data balance, the blueberry patch loss was weighted eight times that of the soil class, and four times the amount of the other classes. We also performed upsampling of the blueberry class by creating 12 new samples for each patch, as detailed in <a href="#sec2dot5-sensors-21-00471">Section 2.5</a>. Finally, the soil class was downsampled to 50% of its original number of patches.</p> <p>Because three orthomosaics were available, a leave-one-mosaic-out cross validation approach was applied in order to evaluate the results. One of the orthomosaics was used for training, another for validation and the last one for testing. In order to ensure that all orthomosaics were used at least once for training, validation, and testing, we rotated them accordingly. This section presents the averages results for the TPR and the accuracy results of the three testing stages that correspond to each orthomosaic.</p> <p>By using the optimal settings that are presented in this section, the model improved from a low TPR value of 63.8% for the blueberry class when no data balancing was applied to a value of 93.39%. In both cases, the overall accuracy for all classes remained similar (98.83% and 98.10%, respectively). Furthermore, it could be observed that unfreezing the weights had a positive effect on the TPR. The best TPR value for the <i>frozen</i> weights was 37.12% without data augmentation while maintaining an overall high accuracy value of 98.01%. However, when using high data augmentation with <i>frozen</i> weights, the best TPR value of 87.99% was obtained at the expense of a lower overall accuracy value of 75.20%. These results suggest that ImageNet weights can be used for this problem, but they need to be updated (and <i>unfrozen</i>) when using data augmentation to focus on blueberry bushes due to the differences in images.</p> <p>Regarding the refinement step of the algorithm, <a href="#sensors-21-00471-f008">Figure 8</a> presents an example of the obtained results. For most of the predicted patches, the segmentation that was obtained with the refined version of the algorithm is much closer to the manual annotation. However, in a few cases, some of the bushes that had originally been detected are missed after the refinement. <a href="#sensors-21-00471-t003">Table 3</a> presents the detailed results of these two issues.</p> <p>On the one hand, the Dice coefficient, which evaluates the overlap and number of non-GT pixels that are contained in the predicted patches, improved significantly with the refinement algorithm from values around 0.2 to values in the 0.5–0.6 range. On the other hand, the ratio of GT pixels that are covered by the mask, which ranges from 0.88 to 0.95 for the non-refined mask was slightly inferior in the refined version (0.78 to 0.87).</p> </div> </div> <div class="discussion" title="discussion"> <div class="title" tagx="title" title="title">
4. Discussion</div> <p>The applied methodology used UAVs to gather information in a restricted access area. Techniques from several research areas were then applied in order to gain knowledge regarding the distribution and properties of the bushes of the invasive blueberry species. In this section, the results that are presented in <a href="#sec3-sensors-21-00471">Section 3</a> are interpreted in order to assess the stage of the invasion in each of the mosaics.</p> <div class="4.1.difficultieswithdata" title="sec"> <div class="title" tagx="title" title="title">
4.1. Difficulties with Data</div> <p>Blueberry plants show a characteristic red leaf colour in autumn, which make them easily recognisable and identifiable in comparison to other classes of vegetation. Both a simple identification and segmentation by colour were proposed and applied in one of the first segmentation approaches. However, partly visible soil with reddish tones constrained blueberry identification. This problem was especially critical for small blueberry bushes. In autumn, the leaf colours can vary between red, red with a yellowish tone, and partly black. This caused challenges for the annotations and for the deep learning algorithm, since the number of blueberry images was already low in comparison to the other classes and it made the colour approach not usable for this study. Further complications were given by light conditions during image taking. When the blueberry bushes had brighter red colours due to sun light, it was difficult to distinguish them from the ground. Bushes, which were located in the shadows, especially the ones that had a predominately black colour, were barely recognisable.</p> <p>The analysis presented some difficulties in the calculations of the height and surface area of the blueberry bushes. The main problems to determine bush height are occlusions, due to nearby trees and difficulties due to dense floor covering vegetation. As the cluster analysis shows, the high density of blueberry bushes in some areas and their proximity increased the possibilities that the bushes were partly covered and the whole bush area was not visible, as already pointed out by [<a href="#B10-sensors-21-00471">10</a>]. Furthermore, bushes were often located close to trees that have canopies that can cover most of a blueberry bush. The areas calculated for the blueberry bushes, exceeding 4–5 m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span>, indicated that there has to be more than one bush, which was difficult to identify in the images, as well as for calculating the height. Wetland regions, imaged in the orthomosaics are grassland and covered with dense hassocks. Therefore, the soil is often not visible and the ground annotations often represent the height of the hassocks, which resulted in values of 0 m maximum height and even more bushes showed a value of 0 m, when the median height was calculated for smaller bushes, especially in B4 and B6. Therefore, it is assumed that the hassocks can reduce the real height of the bushes by 30 cm. However, the calculated height values exceeded 3 m, which is unusual for the blueberry species that are studied here. There were errors produced when the annotations contained parts of an overlapping tree canopy, which increased the maximum height. The median height was resistant to outlier values. When ground areas were annotated, the median generally decreased the height values, especially for small bushes. Annotations of the ground need to be set carefully, since the wetland was uneven and depressions could increase the height values of the blueberry bushes. Furthermore, the differences between the max. height and median height can be influenced by the structure of the bush canopy. Because of these difficulties, a correlation between the height and area values of blueberry bushes was not considered, but a comparison of the distribution of these values showed that the distribution was similar and the bush area was larger than the height.</p> <p>Even though these values are estimations, the applied methodology gave a good overview over a large study area, which cannot otherwise be done by extensive field measurements due to wetland protection regulations. Therefore, despite the difficulties, the achieved results emphasised the following discussion of applications and the qualitative use of the introduced methodology.</p> </div> <div class="4.2.applicationinlandscapemanagement" title="sec"> <div class="title" tagx="title" title="title">
4.2. Application in Landscape Management</div> <p>The collection of high resolution images and the gathered information can help to map and visualise the findings of this study. This information can be used in order to easily establish management measures against the further invasion of alien species into the wetlands, as pointed out in previous studies [<a href="#B31-sensors-21-00471">31</a>,<a href="#B35-sensors-21-00471">35</a>].</p> <p>The area that was occupied by blueberry bushes was low in terms of the studied area (covering 1 to 1.5 %), which is lower than the identified 3 to 5% in [<a href="#B15-sensors-21-00471">15</a>]. However, when only the living vegetation was considered, the number of blueberry bushes was found to increase from 8.2 up to 21.1%. These percentages can be considered to be very high, due to the fact that the species is invasive and it does not belong to this sensitive ecosystem. B6 has the largest area and it contains the smallest number of blueberry bushes, with the smallest height and area values measured. Therefore, the invasion seems to be in an early stage and it should be easier to manage. Nevertheless, as shown by persistent homology and the high number of single bushes after clustering, bushes were wide spread, which increases the area where measures against the blueberry bushes need to be considered. The hotspot analysis and density map of B6 indicated that there are some bushes, which are concentrated in a dense spot in the middle of the area and distributed from there homogeneously. These findings allowed for determining that the progress of the blueberry bushes into this site is low.</p> <p>B1 has a similar distribution, while the number of blueberry bushes per hectare is doubled in comparison to B6. The density map showed high densities in the northern part of the orthomosaic and a gradual decrease of blueberry bushes in the southern direction, which was confirmed by the hotspot analysis. The density of the bushes was higher than in B6, but, as indicated by the persistent homology, the spread was greater. This indicates that the blueberries invaded but did not reach every region of the site. Furthermore, the blueberry bushes in B1 have the largest bush area within all studied sites. The identified bushes maturity suggests that the blueberry species has invaded the area a long time ago. Because the density map provided the information that the blueberry bushes are mainly distributed in the north, there must be conditions in the south, which prevented further spread.</p> <p>In comparison, B2, B3, and B4 showed a high spread in the southern direction, because blueberry bushes of various size were found everywhere and there were higher concentration areas and several spreading centres. These findings can be confirmed with the persistent homology and density map, indicating a high progress of the invasion. The three orthomosaics seem to have a homogeneous distribution and a gradual change to lower numbers in the southern direction. However, the significant differences that were found by the hotspot analysis indicate that there are conditions that influence the distribution of the blueberry bushes, as in site B1. In addition, all three orthomosaics show an area with a small density of bushes, which can probably be explained by the high water content in the soil correlated with unsuitable conditions regarding plant growth. The invasion of the blueberry species was characterised as such and far advanced for B2 to B4. Only B4 has smaller bushes that cover a smaller area, which suggests that the invasion is less advanced than for B2 and B3. The spread will probably increase there in the following years.</p> <p>Furthermore, the distribution of the blueberry bushes can be connected to the proximity of trees, especially in B1 to B3, where bushes are mainly found around pine trees and shrubby birches, since birds use these as rest areas and mainly distribute seeds where they rest. An exception is B4, where the trees are located next to depressions that are filled with water, which confirms the unsuitable living conditions for blueberry species. In general, it seems that more blueberry bushes occur when the density of the living vegetation is higher, which can be explained by better living conditions and a better distribution through birds.</p> <p>To sum up the results and interpretations, it was found that B6 showed an early stage of invasion. B1 shows an advanced stage of invasion with limitations in the south, while B2 to B4 show a critical, advanced stage of invasion, since the blueberry bushes can be found in the whole study site. The methodology used here helped to assess the stages of invasion.</p> <p>Our study shows a method for helping preserve a sustainable and adaptive conservation of natural ecosystems. Together with further expert interpretations, a deeper understanding of wetland ecosystems can be achieved [<a href="#B30-sensors-21-00471">30</a>]. The calculated properties, height and area, are indices that can be used for plant growth monitoring [<a href="#B46-sensors-21-00471">46</a>], and, therefore, they provide useful information for the practical management of wetlands.</p> </div> <div class="4.3.contributiontoinvasiveblueberrystudiesinwetlands" title="sec"> <div class="title" tagx="title" title="title">
4.3. Contribution to Invasive Blueberry Studies in Wetlands</div> <p>Previous studies were conducted to identify areas of blueberry bush invasions. The first studies were done by [<a href="#B9-sensors-21-00471">9</a>,<a href="#B14-sensors-21-00471">14</a>] covering up to 12.5 km<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div></div></span> with estimations of blueberry bush coverage areas. Another study focusing on the invasive blueberry species was presented by [<a href="#B15-sensors-21-00471">15</a>], studying an area of 4.7 ha, which is nine times smaller than the area that was studied in our work. Reference [<a href="#B10-sensors-21-00471">10</a>] studied an area of 230 ha and characterised the blueberry invasion. The author conducted 11 days of fieldwork in order to capture the information regarding the cover area of blueberry bushes. The study area is less in our work with 63 ha, but, in comparison to the manual fieldwork, image capturing only took half a day. The pre-processing step needed the longest time, about 4 to 5 h per orthomosaic, since manual annotations were done in the beginning of the work. Therefore, the presented workflow of our study reduces the amount of time for gathering information significantly. The characteristics that were provided by [<a href="#B10-sensors-21-00471">10</a>] are mainly focused on the blueberry bush cover area, which were 16% of the 230 ha. Other characteristics were provided by general statements about average heights and clustering behaviours. Our study provided height and area measurements for each blueberry bush, which has not been done in previous studies. Based on the orthomosaics, further measures, like hot spot analysis, density calculations, and spread measures, could be performed in order to characterise the blueberry invasion in much more detail than previous studies have shown [<a href="#B10-sensors-21-00471">10</a>,<a href="#B15-sensors-21-00471">15</a>]. Furthermore, refs. [<a href="#B10-sensors-21-00471">10</a>,<a href="#B15-sensors-21-00471">15</a>] stated a high probability of loss of identification during fieldwork due to the density of the bushes in certain areas near former blueberry plantations, which were therefore predominantly investigated. In comparison to the mentioned studies, our work presents an objective grading, a precise cover area and each bush was detected in the captured high-resolution images. This information is essential in order to compare both the invasion and monitoring in different areas.</p> </div> <div class="4.4.automaticmasksgeneration" title="sec"> <div class="title" tagx="title" title="title">
4.4. Automatic Masks Generation</div> <p>Deep learning techniques were used in order to assess whether DNN can be used to automatically detect the presence of blueberry bushes. Since the manual annotation of the blueberry bushes is the most time-consuming step of this workflow, this has the potential to greatly extend the range of studies. The results in <a href="#sec3dot2-sensors-21-00471">Section 3.2</a> show that the ResNet50 network succeeded at the classification tasks associated to our problem and that the best results were obtained by re-training the whole network. In this respect, relying on pre-trained weights from ImageNet to solve our problem after minor re-training of the last layer is suboptimal. A dataset must be large enough to re-train the full networks. In our case, this meant using images that were taken from three orthomosaics covering a total of 33 hectares.</p> <p>At the same time, the results also quantify how a data imbalance may result in a network that classifies most of the patches correctly, wven if the blueberry bushes were mainly misclassified. To address this problem, data augmentation as well as a loss function that took into account the number of pixels for each class were used to influence the weights which helped to reduce bias of the training towards the correct classification of blueberry bushes.</p> <p>Wetland image classification was performed by [<a href="#B36-sensors-21-00471">36</a>,<a href="#B37-sensors-21-00471">37</a>] identifying four and six classes, reaching an overall accuracy of 94.82% and 82.02%. Transfer learning which was only applied in [<a href="#B36-sensors-21-00471">36</a>] showed the effectiveness of this technique for natural environment studies, when the dataset is large enough. Interestingly, the best result of [<a href="#B37-sensors-21-00471">37</a>] was obtained when using multi-view images. We will consider this type of images in our future work. A similar approach to detect invasive species was used by [<a href="#B38-sensors-21-00471">38</a>]. Their approach applied deep learning with data augmentation and transfer learning. Their highest accuracy was 97.6%, which is slightly lower than our overall accuracies of 98.83% and 98.10%. It is important to consider that, in [<a href="#B38-sensors-21-00471">38</a>], the dataset was mainly composed of images of the invasive species, while, in our case, only 2.64% of the generated patches contained the invasive species. This illustrates the effectiveness of the techniques used in our approach to overcome the imbalance in our dataset.</p> <p>The results of the automatic classification were used in order to map the invasive species, which is an important first step, whereby a refined segmentation is essential to effectively determine the exact location of plant invasions [<a href="#B35-sensors-21-00471">35</a>]. The deep learning applications used classified images, and a refined mask provided the blueberry bush locations. The refinement step was necessary in this application, since most of the blueberry bushes are small. Hence, the refined mask offered a more precise localisation of the blueberry bushes. Even though not all bushes were found and some soil areas were misclassified as blueberry bushes, the refined mask could significantly reduce the time of manual annotations and provide maps of the studied area. Increasing the amount of blueberry data can help to optimize the classification accuracy and the localisation of blueberry bushes. This will be considered in our future research.</p> <p>The generation of automatic annotation masks, as performed here, will allow for large scale studies with a minimum of disturbances in the studied environment. Therefore, UAVs and image analysis provide accurate and cost-effective surveys that are needed when studying invasive species [<a href="#B31-sensors-21-00471">31</a>]. The used techniques provided more information than that gathered by previous field surveys in wetland areas [<a href="#B10-sensors-21-00471">10</a>,<a href="#B14-sensors-21-00471">14</a>].</p> </div> <div class="4.5.limitationandfutureworks" title="sec"> <div class="title" tagx="title" title="title">
4.5. Limitation and Future Works</div> <p>The presented work provided a methodology to analyse invasive species from UAV images. Nevertheless, we faced limitations regarding the data that are described in <a href="#sec4dot1-sensors-21-00471">Section 4.1</a>. The autumn season seemed to be a good timing for image taking, but the difficulties regarding the varying colour of the blueberry bushes should be taken into account more carefully. Image taking could be done when the weather is cloudy and not windy, as suggested in previous studies [<a href="#B47-sensors-21-00471">47</a>,<a href="#B48-sensors-21-00471">48</a>]. The chosen flight height of 50 m resulted in high-resolution images, which created heavy orthomosaics. The resolution was reduced to 5–7 cm/pixel to be able to use image processing software. This led to difficulties in identifying blueberry bushes and their properties. For the future, different flight settings can be tested, as presented in [<a href="#B49-sensors-21-00471">49</a>,<a href="#B50-sensors-21-00471">50</a>], especially smaller flight areas and a reduced flight height can help to increase the resolution and precision of the results of blueberry bush properties.</p> <p>The use of deep learning proved to be effective for this problem, but also challenging. As in all artificial intelligence approaches, a sufficient number of images that represent the variability of the desired target is necessary in order to train a supervised model that is usable in practice (in the current studies, this amounted to images that corresponded to 33 hectares). Furthermore, with the size of the current blueberry bush data in these images, careful use of data augmentation as well as a dedicated balancing approach was necessary. In order to improve the detection of blueberry bushes, a larger training dataset would likely be needed. For instance, because blueberry bushes are often planted for blueberry production, those fields could offer a good opportunity to collect new images.</p> <p>Therefore, the detailed mapping within this study can further improve the results of the current status of the blueberry species invasion. Repeated data collection in the same area, as planned, will provide a year-to-year comparison, which will allow for the monitoring and analysis of the ongoing spread in the wetlands. Changes will be easily detectable within the wetlands and the studied blueberry species without disturbances of vulnerable plant and animal species and habitats, as already mentioned by [<a href="#B30-sensors-21-00471">30</a>,<a href="#B35-sensors-21-00471">35</a>].</p> </div> </div> <div class="conclusions" title="conclusions"> <div class="title" tagx="title" title="title">
5. Conclusions</div> <p>In this paper, we introduced a multi-disciplinary methodology to quantitatively evaluate the role of plant species in ecosystems, including invasive species. The use of UAVs makes the approach applicable, even in restricted access areas and it increases the total area that can be studied, greatly exceeding the range of existing field studies. We used this methodology to gather information regarding wetland vegetation. Simple and time-saving methods were applied to classify vegetation and provide information about the properties of the invasive blueberry species found in our study site. The distribution of blueberry bushes was analysed in terms of their density, clustering, and spread. The relative importance of blueberries in the wetland was analysed (number of bushes, bush area, and bush height). This information was transformed into location, density, and hotspot maps to provide advanced visualization tools. Deep learning techniques were used in order to automatically detect and segment blueberry bushes, opening the possibility to further extend the range of similar studies.</p> </div> </div> <div class="back" title="back"> <div class="ack" title="ack"> <div class="title" tagx="title" title="title">
Acknowledgments</div> <p>The publication of this article was funded by the Open Access Fund of the Leibniz Universität Hannover. We thank Angie Faust for language corrections and Thomas Beuster (ÖSSM - Ecological protection station Steinhuder Meer) for the opportunity to take aerial photography in the study site and for his helpful contributions to the ecology of blueberries in the Lichtenmoor.</p> </div> <div class="fn-group" title="fn-group"> <div class="fn-type-" title=""> <p><b>Publisher’s Note:</b> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p> </div> </div> <div class="title" tagx="title" title="title">
Author Contributions</div> <p>S.K., M.C., L.T., J.G., B.B., K.W., M.L.L.C. and Y.D., conceived the conceptualization and methodology, supported the writing—review and editing. S.K., M.C. and Y.D. developed the software, performed the validation, investigation and writing—original draft preparation. S.K., M.C. and Y.D. carried out formal analysis. S.K. was in charge of the visualisations. S.K., and J.G. administrated the data. J.G, B.B., M.L.L.C. and Y.D. supervised the project and provided resources. J.G., B.B. and Y.D. directed the project administration. All authors have read and agreed to the published version of the manuscript.</p> <div class="title" tagx="title" title="title">
Funding</div> <p>This research received no external funding.</p> <div class="title" tagx="title" title="title">
Institutional Review Board Statement</div> <p>Not applicable.</p> <div class="title" tagx="title" title="title">
Informed Consent Statement</div> <p>Not applicable.</p> <div class="title" tagx="title" title="title">
Data Availability Statement</div> <p>The data presented in this study are available on request from the corresponding author.</p> <div class="title" tagx="title" title="title">
Conflicts of Interest</div> <p>The authors declare no conflict of interest.</p> <div class="references">
References</div> <div tag="ref-list"> <ul> <div class="title" tagx="title" title="title">
References</div> <li tag="ref"><a name="B1-sensors-21-00471" /><span class="label" tagx="label" title="label">1.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Prentis</span><span class="given-names" tagx="given-names" title="given-names">P.J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Wilson</span><span class="given-names" tagx="given-names" title="given-names">J.R.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Dormontt</span><span class="given-names" tagx="given-names" title="given-names">E.E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Richardson</span><span class="given-names" tagx="given-names" title="given-names">D.M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lowe</span><span class="given-names" tagx="given-names" title="given-names">A.J.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Adaptive evolution in invasive species</span><span class="source" tagx="source" title="source">Trends Plant Sci.</span><span class="year" tagx="year" title="year">2008</span><span class="volume" tagx="volume" title="volume">13</span><span class="fpage" tagx="fpage" title="fpage">288</span><span class="lpage" tagx="lpage" title="lpage">294</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.tplants.2008.03.004">10.1016/j.tplants.2008.03.004</a></span><span class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18467157">18467157</a></span></span></li> <li tag="ref"><a name="B2-sensors-21-00471" /><span class="label" tagx="label" title="label">2.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Pyšek</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Richardson</span><span class="given-names" tagx="given-names" title="given-names">D.M.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Invasive Species, Environmental Change and Management, and Health</span><span class="source" tagx="source" title="source">Annu. Rev. Environ. Resour.</span><span class="year" tagx="year" title="year">2010</span><span class="volume" tagx="volume" title="volume">35</span><span class="fpage" tagx="fpage" title="fpage">25</span><span class="lpage" tagx="lpage" title="lpage">55</span><span class="pub-id"><a href="https://dx.doi.org/10.1146/annurev-environ-033009-095548">10.1146/annurev-environ-033009-095548</a></span></span></li> <li tag="ref"><a name="B3-sensors-21-00471" /><span class="label" tagx="label" title="label">3.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Pimentel</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Zuniga</span><span class="given-names" tagx="given-names" title="given-names">R.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Morrison</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Update on the environmental and economic costs associated with alien-invasive species in the United States</span><span class="source" tagx="source" title="source">Ecol. Econ.</span><span class="year" tagx="year" title="year">2005</span><span class="volume" tagx="volume" title="volume">52</span><span class="fpage" tagx="fpage" title="fpage">273</span><span class="lpage" tagx="lpage" title="lpage">288</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.ecolecon.2004.10.002">10.1016/j.ecolecon.2004.10.002</a></span></span></li> <li tag="ref"><a name="B4-sensors-21-00471" /><span class="label" tagx="label" title="label">4.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Caffrey</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Baars</span><span class="given-names" tagx="given-names" title="given-names">J.R.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Barbour</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Boets</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Boon</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Davenport</span><span class="given-names" tagx="given-names" title="given-names">K.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Dick</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Early</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Edsman</span><span class="given-names" tagx="given-names" title="given-names">L.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Gallagher</span><span class="given-names" tagx="given-names" title="given-names">C.</span></span><span class="etal" title="etal"><i>et al.</i></span></span><span class="mixed-article-title" title="mixed-article-title">Tackling Invasive Alien Species in Europe: The Top 20 Issues</span><span class="source" tagx="source" title="source">Manag. Biol. Invasions</span><span class="year" tagx="year" title="year">2014</span><span class="volume" tagx="volume" title="volume">5</span><span class="fpage" tagx="fpage" title="fpage">1</span><span class="lpage" tagx="lpage" title="lpage">20</span><span class="pub-id"><a href="https://dx.doi.org/10.3391/mbi.2014.5.1.01">10.3391/mbi.2014.5.1.01</a></span></span></li> <li tag="ref"><a name="B5-sensors-21-00471" /><span class="label" tagx="label" title="label">5.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Rabitsch</span><span class="given-names" tagx="given-names" title="given-names">W.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Genovesi</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Invasive Alien Species Indicators in Europe; EEA Technical Report; 2012</span><span class="comment">Available online: <a href="https://op.europa.eu/en/publication-detail/-/publication/0e70dca6-0213-4420-b04a-8951cb9a0df7/language-en">https://op.europa.eu/en/publication-detail/-/publication/0e70dca6-0213-4420-b04a-8951cb9a0df7/language-en</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 8 January 2021)</span></span></li> <li tag="ref"><a name="B6-sensors-21-00471" /><span class="label" tagx="label" title="label">6.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Didham</span><span class="given-names" tagx="given-names" title="given-names">R.K.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tylianakis</span><span class="given-names" tagx="given-names" title="given-names">J.M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Hutchison</span><span class="given-names" tagx="given-names" title="given-names">M.A.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Ewers</span><span class="given-names" tagx="given-names" title="given-names">R.M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Gemmell</span><span class="given-names" tagx="given-names" title="given-names">N.J.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Are invasive species the drivers of ecological change?</span><span class="source" tagx="source" title="source">Trends Ecol. Evol.</span><span class="year" tagx="year" title="year">2005</span><span class="volume" tagx="volume" title="volume">20</span><span class="fpage" tagx="fpage" title="fpage">470</span><span class="lpage" tagx="lpage" title="lpage">474</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.tree.2005.07.006">10.1016/j.tree.2005.07.006</a></span><span class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16701420">16701420</a></span></span></li> <li tag="ref"><a name="B7-sensors-21-00471" /><span class="label" tagx="label" title="label">7.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Piria</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Copp</span><span class="given-names" tagx="given-names" title="given-names">G.H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Dick</span><span class="given-names" tagx="given-names" title="given-names">J.T.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Duplić</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Groom</span><span class="given-names" tagx="given-names" title="given-names">Q.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Jelić</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lucy</span><span class="given-names" tagx="given-names" title="given-names">F.E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Roy</span><span class="given-names" tagx="given-names" title="given-names">H.E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Sarat</span><span class="given-names" tagx="given-names" title="given-names">E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Simonović</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="etal" title="etal"><i>et al.</i></span></span><span class="mixed-article-title" title="mixed-article-title">Tackling invasive alien species in Europe II: Threats and opportunities until 2020</span><span class="source" tagx="source" title="source">Manag. Biol. Invasions</span><span class="year" tagx="year" title="year">2017</span><span class="volume" tagx="volume" title="volume">8</span><span class="fpage" tagx="fpage" title="fpage">273</span><span class="lpage" tagx="lpage" title="lpage">286</span><span class="pub-id"><a href="https://dx.doi.org/10.3391/mbi.2017.8.3.02">10.3391/mbi.2017.8.3.02</a></span></span></li> <li tag="ref"><a name="B8-sensors-21-00471" /><span class="label" tagx="label" title="label">8.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Hollenbach</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Verstärktes Vorgehen der Naturschutzbehörde Gegen Die Nordamerikanische Kulturheidelbeere</span><span class="year" tagx="year" title="year">2014</span><span class="comment">Available online: <a href="https://www.nlwkn.niedersachsen.de/naturschutz/fach_und_forderprogramme/life/hannoversche_moorgeest/aktuelles_termine/verstaerktes-vorgehen-der-naturschutzbehoerde-gegen-die-nordamerikanische-kulturheidelbeere-126107.html">https://www.nlwkn.niedersachsen.de/naturschutz/fach_und_forderprogramme/life/hannoversche_moorgeest/aktuelles_termine/verstaerktes-vorgehen-der-naturschutzbehoerde-gegen-die-nordamerikanische-kulturheidelbeere-126107.html</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 11 November 2020)</span></span></li> <li tag="ref"><a name="B9-sensors-21-00471" /><span class="label" tagx="label" title="label">9.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Schepker</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kowarik</span><span class="given-names" tagx="given-names" title="given-names">I.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Invasive North American Blueberry Hybrids (<i>Vaccinium corymbosum</i> x <i>angustifolium</i>) in Northern Germany</span><span class="source" tagx="source" title="source">Plant Invasions: Ecological Mechanisms and Human Responses</span><span class="publisher-name" tagx="publisher-name" title="publisher-name">Backhuys Publishers</span><span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Leiden, The Netherlands</span><span class="year" tagx="year" title="year">1998</span><span class="fpage" tagx="fpage" title="fpage">253</span><span class="lpage" tagx="lpage" title="lpage">260</span></span></li> <li tag="ref"><a name="B10-sensors-21-00471" /><span class="label" tagx="label" title="label">10.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Stieper</span><span class="given-names" tagx="given-names" title="given-names">L.C.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Distribution of Wild Growing Cultivated Blueberries in Krähenmoor and Their Impact on Bog Vegetation and Bog Development</span><span class="source" tagx="source" title="source">Bachelor’s Thesis</span><span class="publisher-name" tagx="publisher-name" title="publisher-name">Leibniz University of Hannover</span><span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Hanover, Germany</span><span class="year" tagx="year" title="year">2018</span></span></li> <li tag="ref"><a name="B11-sensors-21-00471" /><span class="label" tagx="label" title="label">11.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Nehring</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kowarik</span><span class="given-names" tagx="given-names" title="given-names">I.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Rabitsch</span><span class="given-names" tagx="given-names" title="given-names">W.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Essl</span><span class="given-names" tagx="given-names" title="given-names">F.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lippe</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lauterbach</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Seitz</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Isermann</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Etling</span><span class="given-names" tagx="given-names" title="given-names">K.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Naturschutzfachliche Invasivitätsbewertungen für in Deutschland wild lebende gebietsfremde Gefäßpflanzen</span><span class="source" tagx="source" title="source">BfN-Skripten</span><span class="year" tagx="year" title="year">2013</span><span class="volume" tagx="volume" title="volume">352</span><span class="fpage" tagx="fpage" title="fpage">1</span><span class="lpage" tagx="lpage" title="lpage">202</span></span></li> <li tag="ref"><a name="B12-sensors-21-00471" /><span class="label" tagx="label" title="label">12.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Deilmann</span><span class="given-names" tagx="given-names" title="given-names">H.C.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Eichhorn</span><span class="given-names" tagx="given-names" title="given-names">G.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Falkenberg</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Günther</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Hayen</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kuntze</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Pollak</span><span class="given-names" tagx="given-names" title="given-names">E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Schmatzler</span><span class="given-names" tagx="given-names" title="given-names">E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Steffens</span><span class="given-names" tagx="given-names" title="given-names">P.J.T.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Moor und Torf in Niedersachsen</span><span class="source" tagx="source" title="source">Niedersächsische Akad. Geowiss.</span><span class="year" tagx="year" title="year">1990</span><span class="volume" tagx="volume" title="volume">5</span><span class="comment">Available online: <a href="https://www.schweizerbart.de/publications/detail/artno/183010500/Moor-und-Torf-in-Niedersachsen">https://www.schweizerbart.de/publications/detail/artno/183010500/Moor-und-Torf-in-Niedersachsen</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 11 January 2021)</span></span></li> <li tag="ref"><a name="B13-sensors-21-00471" /><span class="label" tagx="label" title="label">13.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kowarik</span><span class="given-names" tagx="given-names" title="given-names">U.S.I.</span></span></span><span class="mixed-article-title" title="mixed-article-title"><i>Vaccinium angustifolium</i> x <i>corymbosum</i></span><span class="year" tagx="year" title="year">2003</span><span class="comment">Available online: <a href="https://neobiota.bfn.de/handbuch/gefaesspflanzen/vaccinium-angustifolim-x-corymbosum.html">https://neobiota.bfn.de/handbuch/gefaesspflanzen/vaccinium-angustifolim-x-corymbosum.html</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 11 November 2020)</span></span></li> <li tag="ref"><a name="B14-sensors-21-00471" /><span class="label" tagx="label" title="label">14.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Schepker</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kowarik</span><span class="given-names" tagx="given-names" title="given-names">I.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Grave</span><span class="given-names" tagx="given-names" title="given-names">E.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Verwilderung nordamerikanischer Kultur-Heidelbeeren (Vaccinium subgen. Cyanococcus) in Niedersachsen und deren Einschätzung aus Naturschutzsicht</span><span class="source" tagx="source" title="source">Nat. Landsch.</span><span class="year" tagx="year" title="year">1997</span><span class="volume" tagx="volume" title="volume">72</span><span class="fpage" tagx="fpage" title="fpage">346</span><span class="lpage" tagx="lpage" title="lpage">351</span></span></li> <li tag="ref"><a name="B15-sensors-21-00471" /><span class="label" tagx="label" title="label">15.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Essl</span><span class="given-names" tagx="given-names" title="given-names">F.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Erstfund eines verwilderten Vorkommens der Kultur-Heidelbeere (<i>Vaccinium angustifolium</i> x <i>corymbosum</i>) in Östereich</span><span class="source" tagx="source" title="source">Linzer Biologische Beiträge</span><span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Austria</span><span class="year" tagx="year" title="year">2004</span><span class="comment">Available online: <a href="https://www.zobodat.at/pdf/LBB_0036_2_0785-0796.pdf">https://www.zobodat.at/pdf/LBB_0036_2_0785-0796.pdf</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 11 January 2021)</span></span></li> <li tag="ref"><a name="B16-sensors-21-00471" /><span class="label" tagx="label" title="label">16.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Grenzdorffer</span><span class="given-names" tagx="given-names" title="given-names">G.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Teichert</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span></span><span class="mixed-article-title" title="mixed-article-title">The photogrammetric potential of low-cost UAVs in forestry and agriculture</span><span class="source" tagx="source" title="source">Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.</span><span class="year" tagx="year" title="year">2008</span><span class="volume" tagx="volume" title="volume">31</span><span class="fpage" tagx="fpage" title="fpage">1207</span><span class="lpage" tagx="lpage" title="lpage">1214</span></span></li> <li tag="ref"><a name="B17-sensors-21-00471" /><span class="label" tagx="label" title="label">17.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Raparelli</span><span class="given-names" tagx="given-names" title="given-names">E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Bajocco</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span></span><span class="mixed-article-title" title="mixed-article-title">A bibliometric analysis on the use of unmanned aerial vehicles in agricultural and forestry studies</span><span class="source" tagx="source" title="source">Int. J. Remote Sens.</span><span class="year" tagx="year" title="year">2019</span><span class="volume" tagx="volume" title="volume">40</span><span class="fpage" tagx="fpage" title="fpage">9070</span><span class="lpage" tagx="lpage" title="lpage">9083</span><span class="pub-id"><a href="https://dx.doi.org/10.1080/01431161.2019.1569793">10.1080/01431161.2019.1569793</a></span></span></li> <li tag="ref"><a name="B18-sensors-21-00471" /><span class="label" tagx="label" title="label">18.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Natesan</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Armenakis</span><span class="given-names" tagx="given-names" title="given-names">C.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Vepakomma</span><span class="given-names" tagx="given-names" title="given-names">U.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Resnet-based tree species classification using UAV images</span><span class="source" tagx="source" title="source">ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</span><span class="year" tagx="year" title="year">2019</span><span class="volume" tagx="volume" title="volume">XLII-2/W13</span><span class="fpage" tagx="fpage" title="fpage">475</span><span class="lpage" tagx="lpage" title="lpage">481</span><span class="pub-id"><a href="https://dx.doi.org/10.5194/isprs-archives-XLII-2-W13-475-2019">10.5194/isprs-archives-XLII-2-W13-475-2019</a></span></span></li> <li tag="ref"><a name="B19-sensors-21-00471" /><span class="label" tagx="label" title="label">19.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Gambella</span><span class="given-names" tagx="given-names" title="given-names">F.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Sistu</span><span class="given-names" tagx="given-names" title="given-names">L.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Piccirilli</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Corposanto</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Caria</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Arcangeletti</span><span class="given-names" tagx="given-names" title="given-names">E.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Proto</span><span class="given-names" tagx="given-names" title="given-names">A.R.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Chessa</span><span class="given-names" tagx="given-names" title="given-names">G.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Pazzona</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Forest and UAV: A bibliometric review</span><span class="source" tagx="source" title="source">Contemp. Eng. Sci.</span><span class="year" tagx="year" title="year">2016</span><span class="volume" tagx="volume" title="volume">9</span><span class="fpage" tagx="fpage" title="fpage">1359</span><span class="lpage" tagx="lpage" title="lpage">1370</span><span class="pub-id"><a href="https://dx.doi.org/10.12988/ces.2016.68130">10.12988/ces.2016.68130</a></span></span></li> <li tag="ref"><a name="B20-sensors-21-00471" /><span class="label" tagx="label" title="label">20.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kentsch</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lopez Caceres</span><span class="given-names" tagx="given-names" title="given-names">M.L.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Serrano</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Roure</span><span class="given-names" tagx="given-names" title="given-names">F.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Diez</span><span class="given-names" tagx="given-names" title="given-names">Y.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Computer Vision and Deep Learning Techniques for the Analysis of Drone-Acquired Forest Images, a Transfer Learning Study</span><span class="source" tagx="source" title="source">Remote Sens.</span><span class="year" tagx="year" title="year">2020</span><span class="volume" tagx="volume" title="volume">12</span><span class="elocation-id" tagx="elocation-id" title="elocation-id">1287</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/rs12081287">10.3390/rs12081287</a></span></span></li> <li tag="ref"><a name="B21-sensors-21-00471" /><span class="label" tagx="label" title="label">21.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Heipke</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Pakzad</span><span class="given-names" tagx="given-names" title="given-names">K.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Straub</span><span class="given-names" tagx="given-names" title="given-names">B.M.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Image Analysis for GIS Data Acquisition</span><span class="source" tagx="source" title="source">Photogramm. Rec.</span><span class="year" tagx="year" title="year">2000</span><span class="volume" tagx="volume" title="volume">16</span><span class="fpage" tagx="fpage" title="fpage">963</span><span class="lpage" tagx="lpage" title="lpage">985</span><span class="pub-id"><a href="https://dx.doi.org/10.1111/0031-868X.00160">10.1111/0031-868X.00160</a></span></span></li> <li tag="ref"><a name="B22-sensors-21-00471" /><span class="label" tagx="label" title="label">22.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Carlsson</span><span class="given-names" tagx="given-names" title="given-names">G.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Persistent Homology and Applied Homotopy Theory</span><span class="source" tagx="source" title="source">arXiv</span><span class="year" tagx="year" title="year">2020</span><span class="pub-id" /></span></li> <li tag="ref"><a name="B23-sensors-21-00471" /><span class="label" tagx="label" title="label">23.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Mahdavi</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Salehi</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Granger</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Amani</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Brisco</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Huang</span><span class="given-names" tagx="given-names" title="given-names">W.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Remote sensing for wetland classification: A comprehensive review</span><span class="source" tagx="source" title="source">GISci. Remote Sens.</span><span class="year" tagx="year" title="year">2018</span><span class="volume" tagx="volume" title="volume">55</span><span class="fpage" tagx="fpage" title="fpage">623</span><span class="lpage" tagx="lpage" title="lpage">658</span><span class="pub-id"><a href="https://dx.doi.org/10.1080/15481603.2017.1419602">10.1080/15481603.2017.1419602</a></span></span></li> <li tag="ref"><a name="B24-sensors-21-00471" /><span class="label" tagx="label" title="label">24.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Wu</span><span class="given-names" tagx="given-names" title="given-names">Q.</span></span></span><span class="mixed-article-title" title="mixed-article-title">2.07-GIS and Remote Sensing Applications in Wetland Mapping and Monitoring</span><span class="source" tagx="source" title="source">Comprehensive Geographic Information Systems</span><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Huang</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span></span><span class="publisher-name" tagx="publisher-name" title="publisher-name">Elsevier</span><span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Oxford, UK</span><span class="year" tagx="year" title="year">2018</span><span class="fpage" tagx="fpage" title="fpage">140</span><span class="lpage" tagx="lpage" title="lpage">157</span></span></li> <li tag="ref"><a name="B25-sensors-21-00471" /><span class="label" tagx="label" title="label">25.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Twumasi</span><span class="given-names" tagx="given-names" title="given-names">Y.A.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Merem</span><span class="given-names" tagx="given-names" title="given-names">E.C.</span></span></span><span class="mixed-article-title" title="mixed-article-title">GIS and Remote Sensing Applications in the Assessment of Change within a Coastal Environment in the Niger Delta Region of Nigeria</span><span class="source" tagx="source" title="source">Int. J. Environ. Res. Public Health</span><span class="year" tagx="year" title="year">2006</span><span class="volume" tagx="volume" title="volume">3</span><span class="fpage" tagx="fpage" title="fpage">98</span><span class="lpage" tagx="lpage" title="lpage">106</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/ijerph2006030011">10.3390/ijerph2006030011</a></span><span class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16823081">16823081</a></span></span></li> <li tag="ref"><a name="B26-sensors-21-00471" /><span class="label" tagx="label" title="label">26.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Lang</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Object-based image analysis for remote sensing applications: Modeling reality—Dealing with complexity</span><span class="source" tagx="source" title="source">Object-Based Image Analysis</span><span class="publisher-name" tagx="publisher-name" title="publisher-name">Springer</span><span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Berlin/Heidelberg, Germany</span><span class="year" tagx="year" title="year">2008</span><span class="fpage" tagx="fpage" title="fpage">3</span><span class="lpage" tagx="lpage" title="lpage">27</span></span></li> <li tag="ref"><a name="B27-sensors-21-00471" /><span class="label" tagx="label" title="label">27.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Joshi</span><span class="given-names" tagx="given-names" title="given-names">C.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">de Leeuw</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">van Duren</span><span class="given-names" tagx="given-names" title="given-names">I.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Remote sensing and GIS applications for mapping and spatial modelling of invasive species</span><span class="source" tagx="source" title="source">Proceedings of the XXth ISPRS Congress: Geo-Imagery Bridging Continents</span><span class="conf-loc" tagx="conf-loc" title="conf-loc">Istanbul, Turkey</span><span class="conf-date" tagx="conf-date" title="conf-date">12–23 July 2004</span><span class="fpage" tagx="fpage" title="fpage">669</span><span class="lpage" tagx="lpage" title="lpage">677</span></span></li> <li tag="ref"><a name="B28-sensors-21-00471" /><span class="label" tagx="label" title="label">28.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Rebelo</span><span class="given-names" tagx="given-names" title="given-names">L.M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Finlayson</span><span class="given-names" tagx="given-names" title="given-names">C.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Nagabhatla</span><span class="given-names" tagx="given-names" title="given-names">N.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Remote sensing and GIS for wetland inventory, mapping and change analysis</span><span class="source" tagx="source" title="source">J. Environ. Manag.</span><span class="year" tagx="year" title="year">2009</span><span class="volume" tagx="volume" title="volume">90</span><span class="fpage" tagx="fpage" title="fpage">2144</span><span class="lpage" tagx="lpage" title="lpage">2153</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.jenvman.2007.06.027">10.1016/j.jenvman.2007.06.027</a></span></span></li> <li tag="ref"><a name="B29-sensors-21-00471" /><span class="label" tagx="label" title="label">29.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Gandhi</span><span class="given-names" tagx="given-names" title="given-names">G.M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Parthiban</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Thummalu</span><span class="given-names" tagx="given-names" title="given-names">N.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Christy</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Ndvi: Vegetation Change Detection Using Remote Sensing and Gis—A Case Study of Vellore District</span><span class="source" tagx="source" title="source">Procedia Comput. Sci.</span><span class="year" tagx="year" title="year">2015</span><span class="volume" tagx="volume" title="volume">57</span><span class="fpage" tagx="fpage" title="fpage">1199</span><span class="lpage" tagx="lpage" title="lpage">1210</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.procs.2015.07.415">10.1016/j.procs.2015.07.415</a></span></span></li> <li tag="ref"><a name="B30-sensors-21-00471" /><span class="label" tagx="label" title="label">30.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Dronova</span><span class="given-names" tagx="given-names" title="given-names">I.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Object-Based Image Analysis in Wetland Research: A Review</span><span class="source" tagx="source" title="source">Remote Sens.</span><span class="year" tagx="year" title="year">2015</span><span class="volume" tagx="volume" title="volume">7</span><span class="fpage" tagx="fpage" title="fpage">6380</span><span class="lpage" tagx="lpage" title="lpage">6413</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/rs70506380">10.3390/rs70506380</a></span></span></li> <li tag="ref"><a name="B31-sensors-21-00471" /><span class="label" tagx="label" title="label">31.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tóthmérész</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Wan</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Wang</span><span class="given-names" tagx="given-names" title="given-names">Q.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Jiang</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Fu</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Yang</span><span class="given-names" tagx="given-names" title="given-names">Y.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Liu</span><span class="given-names" tagx="given-names" title="given-names">X.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Monitoring the Invasion of Spartina alterniflora Using Very High Resolution Unmanned Aerial Vehicle Imagery in Beihai, Guangxi (China)</span><span class="source" tagx="source" title="source">Sci. World J.</span><span class="year" tagx="year" title="year">2014</span><span class="volume" tagx="volume" title="volume">2014</span><span class="fpage" tagx="fpage" title="fpage">638296</span></span></li> <li tag="ref"><a name="B32-sensors-21-00471" /><span class="label" tagx="label" title="label">32.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Boon</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Greenfield</span><span class="given-names" tagx="given-names" title="given-names">R.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tesfamichael</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Wetland assessment using unmanned aerial vehicle (UAV) photogrammetry</span><span class="source" tagx="source" title="source">ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</span><span class="year" tagx="year" title="year">2016</span><span class="volume" tagx="volume" title="volume">XLI-B1</span><span class="fpage" tagx="fpage" title="fpage">781</span><span class="lpage" tagx="lpage" title="lpage">788</span><span class="pub-id"><a href="https://dx.doi.org/10.5194/isprsarchives-XLI-B1-781-2016">10.5194/isprsarchives-XLI-B1-781-2016</a></span></span></li> <li tag="ref"><a name="B33-sensors-21-00471" /><span class="label" tagx="label" title="label">33.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Boon</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Greenfield</span><span class="given-names" tagx="given-names" title="given-names">R.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tesfamichael</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Unmanned Aerial Vehicle (UAV) photogrammetry produces accurate high-resolution orthophotos, point clouds and surface models for mapping wetlands</span><span class="source" tagx="source" title="source">South Afr. J. Geomat.</span><span class="year" tagx="year" title="year">2016</span><span class="volume" tagx="volume" title="volume">5</span><span class="fpage" tagx="fpage" title="fpage">186</span><span class="pub-id"><a href="https://dx.doi.org/10.4314/sajg.v5i2.7">10.4314/sajg.v5i2.7</a></span></span></li> <li tag="ref"><a name="B34-sensors-21-00471" /><span class="label" tagx="label" title="label">34.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Dvořák</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Müllerová</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Bartaloš</span><span class="given-names" tagx="given-names" title="given-names">T.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Brůna</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Unmanned aerial vehicles for alien plant species detection and monitoring</span><span class="source" tagx="source" title="source">Remote Sens. Spat. Inf. Sci.</span><span class="year" tagx="year" title="year">2015</span><span class="volume" tagx="volume" title="volume">XL-1/W42015</span><span class="pub-id"><a href="https://dx.doi.org/10.5194/isprsarchives-XL-1-W4-83-2015">10.5194/isprsarchives-XL-1-W4-83-2015</a></span></span></li> <li tag="ref"><a name="B35-sensors-21-00471" /><span class="label" tagx="label" title="label">35.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Mafanya</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tsele</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Botai</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Manyama</span><span class="given-names" tagx="given-names" title="given-names">P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Swart</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Monate</span><span class="given-names" tagx="given-names" title="given-names">T.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Evaluating pixel and object based image classification techniques for mapping plant invasions from UAV derived aerial imagery: Harrisia pomanensis as a case study</span><span class="source" tagx="source" title="source">ISPRS J. Photogramm. Remote Sens.</span><span class="year" tagx="year" title="year">2017</span><span class="volume" tagx="volume" title="volume">129</span><span class="fpage" tagx="fpage" title="fpage">1</span><span class="lpage" tagx="lpage" title="lpage">11</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.isprsjprs.2017.04.009">10.1016/j.isprsjprs.2017.04.009</a></span></span></li> <li tag="ref"><a name="B36-sensors-21-00471" /><span class="label" tagx="label" title="label">36.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Rezaee</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Mahdianpari</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Zhang</span><span class="given-names" tagx="given-names" title="given-names">Y.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Salehi</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Deep Convolutional Neural Network for Complex Wetland Classification Using Optical Remote Sensing Imagery</span><span class="source" tagx="source" title="source">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.</span><span class="year" tagx="year" title="year">2018</span><span class="volume" tagx="volume" title="volume">11</span><span class="fpage" tagx="fpage" title="fpage">3030</span><span class="lpage" tagx="lpage" title="lpage">3039</span><span class="pub-id"><a href="https://dx.doi.org/10.1109/JSTARS.2018.2846178">10.1109/JSTARS.2018.2846178</a></span></span></li> <li tag="ref"><a name="B37-sensors-21-00471" /><span class="label" tagx="label" title="label">37.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Liu</span><span class="given-names" tagx="given-names" title="given-names">T.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Abd-Elrahman</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Deep convolutional neural network training enrichment using multi-view object-based analysis of Unmanned Aerial systems imagery for wetlands classification</span><span class="source" tagx="source" title="source">ISPRS J. Photogramm. Remote Sens.</span><span class="year" tagx="year" title="year">2018</span><span class="volume" tagx="volume" title="volume">139</span><span class="fpage" tagx="fpage" title="fpage">154</span><span class="lpage" tagx="lpage" title="lpage">170</span><span class="pub-id"><a href="https://dx.doi.org/10.1016/j.isprsjprs.2018.03.006">10.1016/j.isprsjprs.2018.03.006</a></span></span></li> <li tag="ref"><a name="B38-sensors-21-00471" /><span class="label" tagx="label" title="label">38.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Ashqar</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Abu-Naser</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Identifying Images of Invasive Hydrangea Using Pre-Trained Deep Convolutional Neural Networks</span><span class="source" tagx="source" title="source">Int. J. Acad. Dev.</span><span class="year" tagx="year" title="year">2019</span><span class="volume" tagx="volume" title="volume">3</span><span class="fpage" tagx="fpage" title="fpage">28</span><span class="lpage" tagx="lpage" title="lpage">36</span><span class="pub-id"><a href="https://dx.doi.org/10.33832/ijca.2019.12.4.02">10.33832/ijca.2019.12.4.02</a></span></span></li> <li tag="ref"><a name="B39-sensors-21-00471" /><span class="label" tagx="label" title="label">39.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Schneekloth</span><span class="given-names" tagx="given-names" title="given-names">H.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tuexen</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Die Moore in Niedersachsen. GOTTINGEN Kommissionsverl. Goettinger Tageblatt, 1975, P. 1 A 198</span><span class="year" tagx="year" title="year">1975</span><span class="comment">Available online: <a href="http://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&amp;idt=PASCALGEODEBRGM7620141242">http://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&amp;amp;idt=PASCALGEODEBRGM7620141242</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 8 January 2021)</span></span></li> <li tag="ref"><a name="B40-sensors-21-00471" /><span class="label" tagx="label" title="label">40.</span><span class="element-citation'"><span class="person-group'"><span class="collab'">collab: Agisoft</span></span><span class="mixed-article-title" title="mixed-article-title">Agisoft Metashape 1.5.5, Professional Edition</span><span class="comment">Available online: <a href="http://www.agisoft.com/downloads/installer/">http://www.agisoft.com/downloads/installer/</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 19 August 2019)</span></span></li> <li tag="ref"><a name="B41-sensors-21-00471" /><span class="label" tagx="label" title="label">41.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Team</span><span class="given-names" tagx="given-names" title="given-names">T.G.</span></span></span><span class="mixed-article-title" title="mixed-article-title">GNU Image Manipulation Program</span><span class="comment">Available online: <a href="http://gimp.org">http://gimp.org</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 19 August 2019)</span></span></li> <li tag="ref"><a name="B42-sensors-21-00471" /><span class="label" tagx="label" title="label">42.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Asaad</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Persistent Homology for Image Analysis</span><span class="source" tagx="source" title="source">Ph.D. Thesis</span><span class="publisher-name" tagx="publisher-name" title="publisher-name">University of Buckingham</span><span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Buckingham, UK</span><span class="year" tagx="year" title="year">2020</span></span></li> <li tag="ref"><a name="B43-sensors-21-00471" /><span class="label" tagx="label" title="label">43.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Cabezas</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kentsch</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tomhave</span><span class="given-names" tagx="given-names" title="given-names">L.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Gross</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Caceres</span><span class="given-names" tagx="given-names" title="given-names">M.L.L.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Diez</span><span class="given-names" tagx="given-names" title="given-names">Y.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Detection of Invasive Species in Wetlands: Practical DL with Heavily Imbalanced Data</span><span class="source" tagx="source" title="source">Remote Sens.</span><span class="year" tagx="year" title="year">2020</span><span class="volume" tagx="volume" title="volume">12</span><span class="elocation-id" tagx="elocation-id" title="elocation-id">3431</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/rs12203431">10.3390/rs12203431</a></span></span></li> <li tag="ref"><a name="B44-sensors-21-00471" /><span class="label" tagx="label" title="label">44.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Jung</span><span class="given-names" tagx="given-names" title="given-names">A.B.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Wada</span><span class="given-names" tagx="given-names" title="given-names">K.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Crall</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Tanaka</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Graving</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Reinders</span><span class="given-names" tagx="given-names" title="given-names">C.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Yadav</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Banerjee</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Vecsei</span><span class="given-names" tagx="given-names" title="given-names">G.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kraft</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span><span class="etal" title="etal"><i>et al.</i></span></span><span class="mixed-article-title" title="mixed-article-title">Imgaug</span><span class="year" tagx="year" title="year">2020</span><span class="comment">Available online: <a href="https://github.com/aleju/imgaug">https://github.com/aleju/imgaug</a></span><span class="date-in-citation" tagx="date-in-citation" title="date-in-citation">(accessed on 1 July 2020)</span></span></li> <li tag="ref"><a name="B45-sensors-21-00471" /><span class="label" tagx="label" title="label">45.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Krizhevsky</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Sutskever</span><span class="given-names" tagx="given-names" title="given-names">I.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Hinton</span><span class="given-names" tagx="given-names" title="given-names">G.E.</span></span></span><span class="mixed-article-title" title="mixed-article-title">ImageNet Classification with Deep Convolutional Neural Networks</span><span class="source" tagx="source" title="source">Commun. ACM</span><span class="year" tagx="year" title="year">2017</span><span class="volume" tagx="volume" title="volume">60</span><span class="fpage" tagx="fpage" title="fpage">84</span><span class="lpage" tagx="lpage" title="lpage">90</span><span class="pub-id"><a href="https://dx.doi.org/10.1145/3065386">10.1145/3065386</a></span></span></li> <li tag="ref"><a name="B46-sensors-21-00471" /><span class="label" tagx="label" title="label">46.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Patrick</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Li</span><span class="given-names" tagx="given-names" title="given-names">C.</span></span></span><span class="mixed-article-title" title="mixed-article-title">High Throughput Phenotyping of Blueberry Bush Morphological Traits Using Unmanned Aerial Systems</span><span class="source" tagx="source" title="source">Remote Sens.</span><span class="year" tagx="year" title="year">2017</span><span class="volume" tagx="volume" title="volume">9</span><span class="elocation-id" tagx="elocation-id" title="elocation-id">1250</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/rs9121250">10.3390/rs9121250</a></span></span></li> <li tag="ref"><a name="B47-sensors-21-00471" /><span class="label" tagx="label" title="label">47.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Zmarz</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span></span><span class="mixed-article-title" title="mixed-article-title">UAV—A useful tool for monitoring woodlands</span><span class="source" tagx="source" title="source">Misc. Geogr.–Reg. Stud. Dev.</span><span class="year" tagx="year" title="year">2013</span><span class="volume" tagx="volume" title="volume">18</span><span class="fpage" tagx="fpage" title="fpage">46</span><span class="lpage" tagx="lpage" title="lpage">52</span><span class="pub-id"><a href="https://dx.doi.org/10.2478/mgrsd-2014-0006">10.2478/mgrsd-2014-0006</a></span></span></li> <li tag="ref"><a name="B48-sensors-21-00471" /><span class="label" tagx="label" title="label">48.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Wierzbicki</span><span class="given-names" tagx="given-names" title="given-names">D.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kedzierski</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Fryskowska</span><span class="given-names" tagx="given-names" title="given-names">A.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Assesment of the influence of uav image quality on the orthophoto production</span><span class="source" tagx="source" title="source">ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</span><span class="year" tagx="year" title="year">2015</span><span class="volume" tagx="volume" title="volume">XL-1/W4</span><span class="fpage" tagx="fpage" title="fpage">1</span><span class="lpage" tagx="lpage" title="lpage">8</span><span class="pub-id"><a href="https://dx.doi.org/10.5194/isprsarchives-XL-1-W4-1-2015">10.5194/isprsarchives-XL-1-W4-1-2015</a></span></span></li> <li tag="ref"><a name="B49-sensors-21-00471" /><span class="label" tagx="label" title="label">49.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Dandois</span><span class="given-names" tagx="given-names" title="given-names">J.P.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Olano</span><span class="given-names" tagx="given-names" title="given-names">M.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Ellis</span><span class="given-names" tagx="given-names" title="given-names">E.C.</span></span></span><span class="mixed-article-title" title="mixed-article-title">Optimal Altitude, Overlap, and Weather Conditions for Computer Vision UAV Estimates of Forest Structure</span><span class="source" tagx="source" title="source">Remote Sens.</span><span class="year" tagx="year" title="year">2015</span><span class="volume" tagx="volume" title="volume">7</span><span class="fpage" tagx="fpage" title="fpage">13895</span><span class="lpage" tagx="lpage" title="lpage">13920</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/rs71013895">10.3390/rs71013895</a></span></span></li> <li tag="ref"><a name="B50-sensors-21-00471" /><span class="label" tagx="label" title="label">50.</span><span class="element-citation'"><span class="person-group'"><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Frey</span><span class="given-names" tagx="given-names" title="given-names">J.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Kovach</span><span class="given-names" tagx="given-names" title="given-names">K.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Stemmler</span><span class="given-names" tagx="given-names" title="given-names">S.</span></span><span class="name" tagx="name" title="name"><span class="surname" tagx="surname" title="surname">Koch</span><span class="given-names" tagx="given-names" title="given-names">B.</span></span></span><span class="mixed-article-title" title="mixed-article-title">UAV Photogrammetry of Forests as a Vulnerable Process. A Sensitivity Analysis for a Structure from Motion RGB-Image Pipeline</span><span class="source" tagx="source" title="source">Remote Sens.</span><span class="year" tagx="year" title="year">2018</span><span class="volume" tagx="volume" title="volume">10</span><span class="elocation-id" tagx="elocation-id" title="elocation-id">912</span><span class="pub-id"><a href="https://dx.doi.org/10.3390/rs10060912">10.3390/rs10060912</a></span></span></li> </ul> </div> </div> <div class="floats-group" title="floats-group"> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 1</span></a></div>   <p>Location of the study area in the north of Germany. In the upper right part of the figure, the study sites are marked with different colours. The bottom right part an example orthomosaic is shown with detail of the different classes.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 2</span></a></div>   <p>Workflow of the paper. Gray is our data base; purple boxes show softwares/programs used in this study; white boxes with a blue outline are generated files; dark blue are processes used for the deep learning (DL) classification and detection; light blue are tools in ArcGIS.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 3</span></a></div>   <p>Image analysis workflow. Consists of two parts, the manual approach using manual annotation, GIS and persistent homology, and the automatic approach while using deep learning and segmentation to analyse the blueberry invasion.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 4</span></a></div>   <p>Distribution of annotated classes for the orthomosaics B1 to B3.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 5</span></a></div>   <p>Distribution of the area and height values of blueberry bushes. From top to bottom: area, maximum height, and median height.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 6</span></a></div>   <p>Density map for the blueberry species for the sites B1 to B3 (location see <a href="#sensors-21-00471-f001">Figure 1</a>). Areas of low densities are marked in green and high densities are red coloured. A gradient between green and red represents values of medium density. White points mark the location of the blueberry bushes.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 7</span></a></div>   <p>The persistent homology is plotted by radius against the region. Four fused regions were considered: 1%, 10%, 50%, and 90% and all sites are plotted.</p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"><a href="http://doi.org/"><span class="label" tagx="label" title="label">Figure 8</span></a></div>   <p>Orthomosaic B1 is displayed with a combination of the manual annotations (black marked spots), the coarse mask (dark grey) and the refined mask (light grey). The red box was zoomed in to show a detailed view on the image and masks.</p>   </div> <div class="table-wrap_UNKNOWN" id="sensors-21-00471-t001" orientation="portrait" position="float">
sensors-21-00471-t001_Table 1<span class="label" tagx="label" title="label">Table 1</span> <p>Area and counting measures of blueberry bushes detected in the orthomosaics.</p>  <table frame="hsides" rules="groups"> <thead> <tr> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1" /> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Orthomosaic Area in ha</th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of Blueberry Bushes</th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Blueberry Bushes per ha</th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Blueberry Bush Area in m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div> </div></div></span></th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Area per Blueberry Bush in m<span class="inline-formula" title="inline-formula"><div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN" /> <div class="mn_UNKNOWN">
2</div> </div> </div> </div></div></span></th> </tr> </thead> <tbody> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B1</td> <td align="center" valign="middle" rowspan="1" colspan="1">11.64</td> <td align="center" valign="middle" rowspan="1" colspan="1">375</td> <td align="center" valign="middle" rowspan="1" colspan="1">32.21</td> <td align="center" valign="middle" rowspan="1" colspan="1">1331.42</td> <td align="center" valign="middle" rowspan="1" colspan="1">3.55</td> <td align="center" valign="middle" rowspan="1" colspan="1" /> </tr> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B2</td> <td align="center" valign="middle" rowspan="1" colspan="1">10.64</td> <td align="center" valign="middle" rowspan="1" colspan="1">687</td> <td align="center" valign="middle" rowspan="1" colspan="1">64.55</td> <td align="center" valign="middle" rowspan="1" colspan="1">1885.51</td> <td align="center" valign="middle" rowspan="1" colspan="1">2.74</td> <td align="center" valign="middle" rowspan="1" colspan="1" /> </tr> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B3</td> <td align="center" valign="middle" rowspan="1" colspan="1">12.47</td> <td align="center" valign="middle" rowspan="1" colspan="1">566</td> <td align="center" valign="middle" rowspan="1" colspan="1">45.40</td> <td align="center" valign="middle" rowspan="1" colspan="1">1470.24</td> <td align="center" valign="middle" rowspan="1" colspan="1">2.60</td> <td align="center" valign="middle" rowspan="1" colspan="1" /> </tr> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B4</td> <td align="center" valign="middle" rowspan="1" colspan="1">12.44</td> <td align="center" valign="middle" rowspan="1" colspan="1">405</td> <td align="center" valign="middle" rowspan="1" colspan="1">32.54</td> <td align="center" valign="middle" rowspan="1" colspan="1">870.33</td> <td align="center" valign="middle" rowspan="1" colspan="1">2.15</td> <td align="center" valign="middle" rowspan="1" colspan="1" /> </tr> <tr> <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">B6</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.14</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">235</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.53</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">278.07</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.18</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1" /> </tr> </tbody> </table> </div> <div class="table-wrap_UNKNOWN" id="sensors-21-00471-t002" orientation="portrait" position="float">
sensors-21-00471-t002_Table 2<span class="label" tagx="label" title="label">Table 2</span> <p>Clustering results that are based on point shapefiles of the sites.</p>  <table frame="hsides" rules="groups"> <thead> <tr> <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1" /> <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">3 m Clustering</th> <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1" /> <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1" /> <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6 m Clustering</th> <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1" /> <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1" /> </tr> <tr> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1" /> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Grouped 3<br /><br /> or More (in %)</th> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of<br /><br /> Single Bushes</th> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Highest Count<br /><br /> in One Group</th> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Grouped 3<br /><br /> or More (in %)</th> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of <br /><br /> Single Bushes</th> <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Highest Count<br /><br /> in One Group</th> </tr> </thead> <tbody> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B1</td> <td align="center" valign="middle" rowspan="1" colspan="1">39.87</td> <td align="center" valign="middle" rowspan="1" colspan="1">89</td> <td align="center" valign="middle" rowspan="1" colspan="1">10</td> <td align="center" valign="middle" rowspan="1" colspan="1">56.63</td> <td align="center" valign="middle" rowspan="1" colspan="1">18</td> <td align="center" valign="middle" rowspan="1" colspan="1">25</td> </tr> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B2</td> <td align="center" valign="middle" rowspan="1" colspan="1">36.82</td> <td align="center" valign="middle" rowspan="1" colspan="1">87</td> <td align="center" valign="middle" rowspan="1" colspan="1">25</td> <td align="center" valign="middle" rowspan="1" colspan="1">69.57</td> <td align="center" valign="middle" rowspan="1" colspan="1">23</td> <td align="center" valign="middle" rowspan="1" colspan="1">50</td> </tr> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B3</td> <td align="center" valign="middle" rowspan="1" colspan="1">35.51</td> <td align="center" valign="middle" rowspan="1" colspan="1">98</td> <td align="center" valign="middle" rowspan="1" colspan="1">33</td> <td align="center" valign="middle" rowspan="1" colspan="1">50.43</td> <td align="center" valign="middle" rowspan="1" colspan="1">36</td> <td align="center" valign="middle" rowspan="1" colspan="1">50</td> </tr> <tr> <td align="left" valign="middle" rowspan="1" colspan="1">B4</td> <td align="center" valign="middle" rowspan="1" colspan="1">28.34</td> <td align="center" valign="middle" rowspan="1" colspan="1">92</td> <td align="center" valign="middle" rowspan="1" colspan="1">9</td> <td align="center" valign="middle" rowspan="1" colspan="1">44.35</td> <td align="center" valign="middle" rowspan="1" colspan="1">39</td> <td align="center" valign="middle" rowspan="1" colspan="1">22</td> </tr> <tr> <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">B6</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">28.28</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">51</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">37.68</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">28</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21</td> </tr> </tbody> </table> </div> <div class="table-wrap_UNKNOWN" id="sensors-21-00471-t003" orientation="portrait" position="float">
sensors-21-00471-t003_Table 3<span class="label" tagx="label" title="label">Table 3</span> <p>Numerical evaluation of the refinement step of the DNN. The rows marked "refined" stand for the algorithm after refinement, while the rows marked "Coarse" correspond to the algorithm without refinement for each of the three studied orthomosaics. The Dice coefficient, as well as the ratio of blueberry pixels in the Ground truth covered by each of the two masks, are presented.</p>  <table frame="hsides" rules="groups"> <thead> <tr> <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Orthomosaic</th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Mask Type</th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Dice</th> <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GT Cover</th> </tr> </thead> <tbody> <tr> <td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">1</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coarse</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.187</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.953</td> </tr> <tr> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Refined</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.526</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.860</td> </tr> <tr> <td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">2</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coarse</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.264</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.949</td> </tr> <tr> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Refined</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.624</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.874</td> </tr> <tr> <td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">3</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coarse</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.223</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.884</td> </tr> <tr> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Refined</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.587</td> <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.789</td> </tr> </tbody> </table> </div> </div>  </body></html>